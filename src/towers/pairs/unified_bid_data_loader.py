import torch
import pandas as pd
import numpy as np
from torch.utils.data import Dataset, DataLoader
from typing import Dict, List, Tuple, Optional
from sqlalchemy.engine import Engine
from tqdm import tqdm

from src.torchrec_preprocess.schema import TorchRecSchema
from src.torchrec_preprocess.torchrec_inputs import slice_and_convert_for_tower
from src.torchrec_preprocess.feature_store import build_feature_store, build_feature_store_with_condition
from src.torchrec_preprocess.feature_projector import FeatureProjector
from src.torchrec_preprocess.feature_preprocessor import FeaturePreprocessor
from torchrec import KeyedJaggedTensor
from data.database_connector import DatabaseConnector


def _build_single_kjt(cat_single: torch.Tensor, keys: List[str]) -> KeyedJaggedTensor:
    """ê°œë³„ ìƒ˜í”Œìš© KJT ìƒì„±"""
    from torchrec import KeyedJaggedTensor
    assert len(cat_single.shape) == 1 and cat_single.shape[0] == len(keys)
    
    values = cat_single
    lengths = torch.ones(len(keys), dtype=torch.int32)
    
    return KeyedJaggedTensor.from_lengths_sync(
        keys=keys,
        values=values,
        lengths=lengths
    )

def _combine_kjts(kjt_list: List[KeyedJaggedTensor]) -> KeyedJaggedTensor:
    """KJT ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ê²°í•©"""
    from torchrec import KeyedJaggedTensor
    
    if not kjt_list:
        raise ValueError("Empty KJT list")
    
    # ëª¨ë“  KJTê°€ ê°™ì€ í‚¤ë¥¼ ê°€ì ¸ì•¼ í•¨
    keys = kjt_list[0].keys()
    
    # ëª¨ë“  valuesì™€ lengthsë¥¼ ê²°í•©
    all_values = []
    all_lengths = []
    
    for kjt in kjt_list:
        all_values.append(kjt.values())
        all_lengths.append(kjt.lengths())
    
    combined_values = torch.cat(all_values)
    combined_lengths = torch.cat(all_lengths)
    
    return KeyedJaggedTensor.from_lengths_sync(
        keys=keys,
        values=combined_values,
        lengths=combined_lengths
    )

def _build_batch_kjt(cat_batch: torch.Tensor, keys: List[str]) -> KeyedJaggedTensor:
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ KJT ìƒì„± (ë²¡í„°í™”)"""
    B, K = cat_batch.shape
    assert K == len(keys), f"Keys length {len(keys)} doesn't match tensor shape {K}"
    
    # ëª¨ë“  ê°’ì„ flatten
    values = cat_batch.reshape(-1)
    
    # ê° í•­ëª©ì€ ê¸¸ì´ 1
    lengths = torch.ones(B * K, dtype=torch.int32)
    
    # í‚¤ë¥¼ Bë²ˆ ë°˜ë³µ
    repeated_keys = keys * B
    
    return KeyedJaggedTensor.from_lengths_sync(
        keys=repeated_keys,
        values=values,
        lengths=lengths
    )


class UnifiedBidDataset(Dataset):
    """
    í†µí•© ìž…ì°° ë°ì´í„°ì…‹ - ìŠ¤íŠ¸ë¦¬ë°ê³¼ ì„ íƒì  í”¼ì²˜ ë¡œë”© ì§€ì›
    
    4ê°€ì§€ ëª¨ë“œ ì§€ì›:
    1. streaming=False, load_all_features=True: ê¸°ì¡´ ë°©ì‹
    2. streaming=False, load_all_features=False: selective loading
    3. streaming=True, load_all_features=True: pairë§Œ ìŠ¤íŠ¸ë¦¬ë°
    4. streaming=True, load_all_features=False: ì™„ì „ ìŠ¤íŠ¸ë¦¬ë° (ê¶Œìž¥)
    """
    def __init__(
        self, 
        db_engine: Engine, 
        schema: TorchRecSchema, 
        limit: Optional[int] = None,
        test_split: float = 0.1,
        is_train: bool = True,
        shuffle: bool = False,
        shuffle_seed: int = 42,
        streaming: bool = False,
        chunk_size: int = 1000,
        load_all_features: bool = True,
        feature_chunksize: int = 5000,  # ì¶”ê°€: í”¼ì²˜ ë¡œë”© ì‹œ ì²­í¬ ì‚¬ì´ì¦ˆ
        feature_limit: Optional[int] = None,  # ì¶”ê°€: í”¼ì²˜ ë¡œë”© ì‹œ ì œí•œ
        shared_feature_stores: Optional[Dict] = None
    ):
        """
        Args:
            streaming: Trueë©´ pairë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
            chunk_size: ìŠ¤íŠ¸ë¦¬ë° ì‹œ ì²­í¬ í¬ê¸°
            load_all_features: Falseë©´ í•„ìš”í•œ í”¼ì²˜ë§Œ ì„ íƒì  ë¡œë”©
        """
        self.db_engine = db_engine
        self.schema = schema
        self.is_train = is_train
        self.streaming = streaming
        self.chunk_size = chunk_size
        self.load_all_features = load_all_features
        self.feature_chunksize = feature_chunksize
        self.feature_limit = feature_limit
        self.shared_feature_stores = shared_feature_stores
        self.preprocessed_stores = None  # ì „ì²˜ë¦¬ëœ ìŠ¤í† ì–´ ì €ìž¥ìš©
        self._worker_id = None  # ì›Œì»¤ ID ì¶”ì 
        
        print(f"UnifiedBidDataset ì´ˆê¸°í™”... (train={is_train}, streaming={streaming}, load_all_features={load_all_features})")
        
        # pairs ë°ì´í„° ì´ˆê¸°í™”
        self.pairs = None
        self.total_count = 0

        if streaming:
            # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: ê°œìˆ˜ì™€ ë²”ìœ„ë§Œ ê³„ì‚°
            self.total_count, self.start_id, self.end_id = self._get_data_info_streaming(limit, test_split)
            self.chunk_cache = {}  # {chunk_id: DataFrame}
            self.pairs = None  # ìŠ¤íŠ¸ë¦¬ë°ì—ì„œëŠ” pairsë¥¼ ë¯¸ë¦¬ ë¡œë“œí•˜ì§€ ì•ŠìŒ
        else:
            # Test mode: shared_feature_storesì— pairsê°€ ìžˆëŠ”ì§€ ë¨¼ì € í™•ì¸
            if shared_feature_stores is not None and 'pairs_data' in shared_feature_stores:
                pairs_data = shared_feature_stores['pairs_data']
                if is_train:
                    self.pairs = pairs_data['train_pairs']
                else:
                    self.pairs = pairs_data['test_pairs']
                self.total_count = len(self.pairs) if self.pairs is not None else 0
                print(f"Test mode pairs ì‚¬ìš©: {self.total_count} pairs")
            else:
                # ê¸°ì¡´ ëª¨ë“œ: ì „ì²´ pairs ë¡œë“œ
                self.pairs = self._load_positive_pairs_static(limit, test_split, shuffle, shuffle_seed)
                self.total_count = len(self.pairs)
        
        # í”¼ì²˜ ë¡œë”©
        if load_all_features:
            if shared_feature_stores is not None:
                print("ê³µìœ  í”¼ì²˜ ìŠ¤í† ì–´ ì‚¬ìš©")
                # Preprocessed storesë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
                if 'preprocessed' in shared_feature_stores:
                    print("  - Preprocessed ìŠ¤í† ì–´ ì‚¬ìš©")
                    self.preprocessed_stores = shared_feature_stores['preprocessed']
                    self.notice_store = self.preprocessed_stores['notice']
                    self.company_store = self.preprocessed_stores['company']
                    self._build_id_mappings(self.notice_store, self.company_store)
                else:
                    # Test mode: raw stores + projection í•„ìš”
                    self.notice_store = shared_feature_stores['notice']
                    self.company_store = shared_feature_stores['company']
                    self._build_id_mappings(self.notice_store, self.company_store)
                    self._setup_projectors()

                    # Test mode: raw ë°ì´í„°ë¥¼ projectioní•˜ì—¬ dense_projected ìƒì„±
                    print("  - Test mode: raw ë°ì´í„° projection ì¤‘...")
                    self._project_raw_features()
            else:
                print("ê°œë³„ í”¼ì²˜ ìŠ¤í† ì–´ ë¡œë”©")
                self._load_all_features()
        else:
            if streaming:
                print("ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì—ì„œëŠ” í”¼ì²˜ë¥¼ ì²­í¬ë³„ë¡œ ë™ì  ë¡œë”©í•©ë‹ˆë‹¤.")
                self._prepare_dynamic_feature_loading()
            else:
                self._load_selective_features_static()
        
        print(f"ì´ {self.total_count}ê°œ pair ì¤€ë¹„ ì™„ë£Œ")
        
    def _get_data_info_streaming(self, limit: Optional[int], test_split: float) -> Tuple[int, int, int]:
        """ìŠ¤íŠ¸ë¦¬ë°ìš© ë°ì´í„° ì •ë³´ ì¡°íšŒ"""
        if limit:
            count_query = f"""
            SELECT COUNT(*) as total_count, MIN(id) as min_id, MAX(id) as max_id
            FROM (
                SELECT id FROM {self.schema.pair.table} 
                ORDER BY id LIMIT {limit}
            ) subq
            """
        else:
            count_query = f"""
            SELECT COUNT(*) as total_count, MIN(id) as min_id, MAX(id) as max_id
            FROM {self.schema.pair.table}
            """
        
        result = pd.read_sql(count_query, self.db_engine).iloc[0]
        total_count = int(result['total_count'])
        min_id = int(result['min_id'])
        max_id = int(result['max_id'])
        
        if test_split == 0:
            return total_count, min_id, max_id
        
        n_test = int(total_count * test_split)
        n_train = total_count - n_test
        
        if self.is_train:
            start_offset = n_test
            id_query = f"""
            SELECT id FROM {self.schema.pair.table} 
            ORDER BY id OFFSET {start_offset} LIMIT 1
            """
            start_id = int(pd.read_sql(id_query, self.db_engine).iloc[0]['id'])
            return n_train, start_id, max_id
        else:
            return n_test, min_id, min_id + n_test - 1
    
    def _load_positive_pairs_static(self, limit: Optional[int], test_split: float, shuffle: bool, shuffle_seed: int) -> pd.DataFrame:
        """ê¸°ì¡´ ë°©ì‹ì˜ static pair ë¡œë”©"""
        query = f"""
        SELECT bidntceno, bidntceord, bizno 
        FROM {self.schema.pair.table}
        ORDER BY id
        """
        
        if limit:
            query += f" LIMIT {limit}"
            
        pairs_df = pd.read_sql(query, self.db_engine)
        
        if shuffle:
            pairs_df = pairs_df.sample(frac=1, random_state=shuffle_seed).reset_index(drop=True)
            print(f"ë°ì´í„°ì…‹ ë‚´ë¶€ ì…”í”Œ ì ìš© (seed={shuffle_seed})")
        else:
            print("ë°ì´í„°ì…‹ ë‚´ë¶€ ì…”í”Œ ë¯¸ì ìš©")
            
        
        if test_split == 0:
            return pairs_df
    
    def _ensure_db_connection(self):
        """ì›Œì»¤ë³„ DB ì—°ê²° í™•ì¸ ë° ìž¬ìƒì„±"""
        # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ ì‹¤í–‰
        import torch.utils.data
        worker_info = torch.utils.data.get_worker_info()
        
        if worker_info is not None:
            # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ì¸ ê²½ìš°
            if self._worker_id != worker_info.id:
                # ìƒˆ ì›Œì»¤ì´ê±°ë‚˜ ì•„ì§ ì—°ê²°ì´ ì—†ëŠ” ê²½ìš°
                self._worker_id = worker_info.id
                
                # ê¸°ì¡´ ì—°ê²° ì¢…ë£Œ
                if hasattr(self, 'db_engine'):
                    try:
                        self.db_engine.dispose()
                    except:
                        pass
                
                # ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ëª¨ë“œì—ì„œëŠ” DB ìž¬ì—°ê²° ë¶ˆí•„ìš”
                # print("ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ëª¨ë“œ: DB ìž¬ì—°ê²° ìƒëžµ")  # ë¡œê·¸ ì œê±°
    
    def _load_all_features(self):
        """ëª¨ë“  í”¼ì²˜ ë¯¸ë¦¬ ë¡œë”©"""
        print("ì „ì²´ í”¼ì²˜ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        notice_store = build_feature_store(
            self.db_engine, self.schema.notice, 
            chunksize=self.feature_chunksize, limit=self.feature_limit, show_progress=True
        )
        
        company_store = build_feature_store(
            self.db_engine, self.schema.company, 
            chunksize=self.feature_chunksize, limit=self.feature_limit, show_progress=True
        )
        
        self._build_id_mappings(notice_store, company_store)
        self.notice_store = notice_store
        self.company_store = company_store
        self._setup_projectors()
        
    def _prepare_dynamic_feature_loading(self):
        """ë™ì  í”¼ì²˜ ë¡œë”© ì¤€ë¹„ (ìŠ¤íŠ¸ë¦¬ë° + selective)"""
        self.feature_cache = {}  # {chunk_id: {'notice_store': ..., 'company_store': ...}}
        self.notice_store = None
        self.company_store = None
        self._setup_projectors()
        
    def _load_selective_features_static(self):
        """ì •ì  selective í”¼ì²˜ ë¡œë”© (non-streaming)"""
        unique_notices = self.pairs[['bidntceno', 'bidntceord']].drop_duplicates()
        unique_companies = self.pairs[['bizno']].drop_duplicates()
        
        notice_store = self._build_selective_feature_store(
            self.schema.notice, unique_notices, ['bidntceno', 'bidntceord']
        )
        company_store = self._build_selective_feature_store(
            self.schema.company, unique_companies, ['bizno']
        )
        
        self._build_id_mappings(notice_store, company_store)
        self.notice_store = notice_store
        self.company_store = company_store
        self._setup_projectors()
        
    def _load_selective_features_for_chunk(self, chunk_df: pd.DataFrame) -> Tuple[Dict, Dict]:
        """ì²­í¬ë³„ selective í”¼ì²˜ ë¡œë”©"""
        unique_notices = chunk_df[['bidntceno', 'bidntceord']].drop_duplicates()
        unique_companies = chunk_df[['bizno']].drop_duplicates()
        
        notice_store = self._build_selective_feature_store(
            self.schema.notice, unique_notices, ['bidntceno', 'bidntceord']
        )
        company_store = self._build_selective_feature_store(
            self.schema.company, unique_companies, ['bizno']
        )
        
        return notice_store, company_store
        
    def _build_selective_feature_store(self, schema, id_df, id_columns):
        """ì„ íƒì  í”¼ì²˜ ìŠ¤í† ì–´ êµ¬ì¶•"""
        if len(id_columns) == 1:
            id_list = id_df[id_columns[0]].astype(str).tolist()
            where_clause = f"{id_columns[0]} IN ({','.join(repr(x) for x in id_list)})"
        else:
            conditions = []
            for _, row in id_df.iterrows():
                condition_parts = []
                for col in id_columns:
                    condition_parts.append(f"{col}='{row[col]}'")
                conditions.append(f"({' AND '.join(condition_parts)})")
            where_clause = f"{' OR '.join(conditions)}"
        
        return build_feature_store_with_condition(
            self.db_engine, schema, where_clause, 
            chunksize=self.feature_chunksize, show_progress=False
        )
    
    def _setup_projectors(self):
        """Projector ì„¤ì •"""
        self.notice_projector = FeatureProjector(
            num_dim=len(self.schema.notice.numeric),
            text_dim=768, num_proj_dim=128, text_proj_dim=128
        )
        self.company_projector = FeatureProjector(
            num_dim=len(self.schema.company.numeric),
            text_dim=768, num_proj_dim=128, text_proj_dim=128
        )
            
    def _build_id_mappings(self, notice_store: Dict, company_store: Dict):
        """ID ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
        if 'ids' not in notice_store:
            raise ValueError("notice_storeì— 'ids' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. build_feature_store() í•¨ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        if 'ids' not in company_store:
            raise ValueError("company_storeì— 'ids' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. build_feature_store() í•¨ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        notice_ids = notice_store['ids']
        self.notice_id_to_idx = {tuple(id_pair): idx for idx, id_pair in enumerate(notice_ids)}
        
        company_ids = company_store['ids']
        if company_ids:
            if isinstance(company_ids[0], (tuple, list)):
                self.company_id_to_idx = {str(id_tuple[0]): idx for idx, id_tuple in enumerate(company_ids)}
            else:
                self.company_id_to_idx = {str(company_id): idx for idx, company_id in enumerate(company_ids)}
    
    def _get_chunk_id(self, idx: int) -> int:
        """ì¸ë±ìŠ¤ë¡œë¶€í„° ì²­í¬ ID ê³„ì‚°"""
        return idx // self.chunk_size
    
    def _load_chunk(self, chunk_id: int) -> Dict[str, np.ndarray]:
        """ì²­í¬ ë¡œë”© (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ) - NumPy ë°°ì—´ë¡œ ë°˜í™˜"""
        # DB ì—°ê²° í™•ì¸ (ì›Œì»¤ë³„ ì—°ê²°)
        self._ensure_db_connection()
        
        start_idx = chunk_id * self.chunk_size
        
        if self.is_train:
            query = f"""
            SELECT bidntceno, bidntceord, bizno, id
            FROM {self.schema.pair.table} 
            WHERE id >= {self.start_id} AND id <= {self.end_id}
            ORDER BY id 
            OFFSET {start_idx} LIMIT {self.chunk_size}
            """
        else:
            query = f"""
            SELECT bidntceno, bidntceord, bizno, id
            FROM {self.schema.pair.table} 
            WHERE id >= {self.start_id} AND id <= {self.end_id}
            ORDER BY id 
            OFFSET {start_idx} LIMIT {self.chunk_size}
            """
        
        chunk_df = pd.read_sql(query, self.db_engine)
        # DataFrameì„ NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return {
            'bidntceno': chunk_df['bidntceno'].values,
            'bidntceord': chunk_df['bidntceord'].values,
            'bizno': chunk_df['bizno'].values,
            'id': chunk_df['id'].values
        }
    
    def _get_pair_data(self, idx: int) -> pd.Series:
        """pair ë°ì´í„° ì¡°íšŒ (streaming/static ëª¨ë“œ í†µí•©)"""
        if self.streaming:
            # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
            chunk_id = self._get_chunk_id(idx)
            
            if chunk_id not in self.chunk_cache:
                # ìºì‹œ í¬ê¸° ì œí•œ
                if len(self.chunk_cache) >= 3:
                    oldest_chunk = min(self.chunk_cache.keys())
                    del self.chunk_cache[oldest_chunk]
                    if not self.load_all_features and oldest_chunk in self.feature_cache:
                        del self.feature_cache[oldest_chunk]
                
                # ìƒˆ ì²­í¬ ë¡œë”© (NumPy ë°°ì—´)
                chunk_arrays = self._load_chunk(chunk_id)
                self.chunk_cache[chunk_id] = chunk_arrays
                
                # ì„ íƒì  í”¼ì²˜ ë¡œë”© (streaming + selective ëª¨ë“œ)
                if not self.load_all_features:
                    # chunk_arraysë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬
                    chunk_df = pd.DataFrame(chunk_arrays)
                    notice_store, company_store = self._load_selective_features_for_chunk(chunk_df)
                    self.feature_cache[chunk_id] = {
                        'notice_store': notice_store,
                        'company_store': company_store,
                        'notice_id_to_idx': {tuple(id_pair): idx for idx, id_pair in enumerate(notice_store['ids'])},
                        'company_id_to_idx': {
                            str(id_tuple[0] if isinstance(id_tuple, (tuple, list)) else id_tuple): idx 
                            for idx, id_tuple in enumerate(company_store['ids'])
                        }
                    }
            
            # ì²­í¬ ë‚´ ì¸ë±ìŠ¤ ê³„ì‚° (NumPy ë°°ì—´ì—ì„œ ì§ì ‘ ì ‘ê·¼)
            chunk_arrays = self.chunk_cache[chunk_id]
            local_idx = idx % self.chunk_size
            
            if local_idx >= len(chunk_arrays['bidntceno']):
                raise IndexError(f"Index {idx} out of range")
            
            # NumPy ë°°ì—´ì—ì„œ ì§ì ‘ ê°’ ì¶”ì¶œ
            return {
                'bidntceno': chunk_arrays['bidntceno'][local_idx],
                'bidntceord': chunk_arrays['bidntceord'][local_idx],
                'bizno': chunk_arrays['bizno'][local_idx]
            }, chunk_id
        else:
            # ì •ì  ëª¨ë“œ
            return self.pairs.iloc[idx], None
    
    def __len__(self) -> int:
        return self.total_count
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """ì•„ì´í…œ ë°˜í™˜ - ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì™€ ì •ì  ëª¨ë“œ êµ¬ë¶„ ì²˜ë¦¬"""
        if idx >= self.total_count:
            raise IndexError(f"Index {idx} out of range (total: {self.total_count})")

        if self.streaming:
            # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: ì²­í¬ì—ì„œ pair ë°ì´í„° ì¡°íšŒ
            chunk_id = self._get_chunk_id(idx)
            if chunk_id not in self.chunk_cache:
                chunk_arrays = self._load_chunk(chunk_id)
                self.chunk_cache[chunk_id] = chunk_arrays

            # ì²­í¬ ìºì‹œì—ì„œ ë¹ ë¥¸ ì¡°íšŒ
            local_idx = idx % self.chunk_size
            chunk_arrays = self.chunk_cache[chunk_id]

            bidntceno = chunk_arrays['bidntceno'][local_idx]
            bidntceord = chunk_arrays['bidntceord'][local_idx]
            bizno = str(chunk_arrays['bizno'][local_idx])
        else:
            # ì •ì  ëª¨ë“œ: pairs DataFrameì—ì„œ ì§ì ‘ ì¡°íšŒ
            pair_row = self.pairs.iloc[idx]
            bidntceno = pair_row['bidntceno']
            bidntceord = pair_row['bidntceord']
            bizno = str(pair_row['bizno'])
        
        # ì¸ë±ìŠ¤ ì¡°íšŒ (Test Modeì—ì„œëŠ” 100% ë§¤ì¹­ ë³´ìž¥)
        notice_key = (bidntceno, bidntceord)
        company_key = bizno

        notice_idx = self.notice_id_to_idx.get(notice_key)
        company_idx = self.company_id_to_idx.get(company_key)

        # Test Modeì—ì„œëŠ” ëˆ„ë½ IDê°€ ìžˆìœ¼ë©´ ëª…í™•ížˆ ì˜¤ë¥˜ ë°œìƒ
        if notice_idx is None:
            raise KeyError(f"Notice ID not found in features: {notice_key}")
        if company_idx is None:
            raise KeyError(f"Company ID not found in features: {company_key}")
        
        return {
            "notice_idx": notice_idx,
            "company_idx": company_idx,
            "pair_info": {"bidntceno": bidntceno, "bidntceord": bidntceord, "bizno": bizno}
        }


def create_collate_fn_original(dataset: 'UnifiedBidDataset'):
    """ì›ë³¸ collate í•¨ìˆ˜ (ë°±ì—…ìš©) - load_all_features=True, streaming=True ì „ìš©"""
    from concurrent.futures import ThreadPoolExecutor
    
    def collate_fn(batch: List[Dict]) -> Dict[str, Dict[str, torch.Tensor]]:
        # ë°°ì¹˜ì—ì„œ ì¸ë±ìŠ¤ë“¤ ì¶”ì¶œ
        notice_indices = [item["notice_idx"] for item in batch]
        company_indices = [item["company_idx"] for item in batch]
        
        # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ noticeì™€ company ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=2) as executor:
            # Notice ì²˜ë¦¬ í•¨ìˆ˜
            def process_notice():
                notice_dense = torch.from_numpy(
                    dataset.notice_store['dense_projected'][notice_indices]
                ).float()
                
                notice_cat = dataset.notice_store['categorical'][notice_indices]
                notice_kjt = _build_batch_kjt(
                    torch.from_numpy(notice_cat).long(),
                    dataset.schema.notice.categorical
                )
                return {"dense": notice_dense, "kjt": notice_kjt}
            
            # Company ì²˜ë¦¬ í•¨ìˆ˜  
            def process_company():
                company_dense = torch.from_numpy(
                    dataset.company_store['dense_projected'][company_indices]
                ).float()
                
                company_cat = dataset.company_store['categorical'][company_indices]
                company_kjt = _build_batch_kjt(
                    torch.from_numpy(company_cat).long(),
                    dataset.schema.company.categorical
                )
                return {"dense": company_dense, "kjt": company_kjt}
            
            # ë³‘ë ¬ ì‹¤í–‰
            future_notice = executor.submit(process_notice)
            future_company = executor.submit(process_company)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            notice_result = future_notice.result()
            company_result = future_company.result()
        
        return {
            "notice": notice_result,
            "company": company_result
        }
    
    return collate_fn


def create_collate_fn_gpu(dataset: 'UnifiedBidDataset'):
    """GPU ì „ìš© collate í•¨ìˆ˜ (pin_memory=False í•„ìš”)"""
    from concurrent.futures import ThreadPoolExecutor
    
    def collate_fn_gpu(batch: List[Dict]) -> Dict[str, Dict[str, torch.Tensor]]:
        # ë°°ì¹˜ì—ì„œ ì¸ë±ìŠ¤ë“¤ ì¶”ì¶œ
        notice_indices = [item["notice_idx"] for item in batch]
        company_indices = [item["company_idx"] for item in batch]
        
        # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ noticeì™€ company ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=2) as executor:
            # Notice ì²˜ë¦¬ í•¨ìˆ˜ (GPU ì§ì ‘ ì „ì†¡)
            def process_notice():
                # Dense ë°ì´í„°: GPU ì§ì ‘ ì „ì†¡
                notice_dense = torch.from_numpy(
                    dataset.notice_store['dense_projected'][notice_indices]
                ).float().cuda()
                
                # Categorical ë°ì´í„°: GPUì—ì„œ KJT ìƒì„±
                notice_cat = dataset.notice_store['categorical'][notice_indices]
                notice_kjt = _build_batch_kjt_gpu(
                    torch.from_numpy(notice_cat).long(),
                    dataset.schema.notice.categorical
                )
                return {"dense": notice_dense, "kjt": notice_kjt}
            
            # Company ì²˜ë¦¬ í•¨ìˆ˜ (GPU ì§ì ‘ ì „ì†¡)
            def process_company():
                # Dense ë°ì´í„°: GPU ì§ì ‘ ì „ì†¡
                company_dense = torch.from_numpy(
                    dataset.company_store['dense_projected'][company_indices]
                ).float().cuda()
                
                # Categorical ë°ì´í„°: GPUì—ì„œ KJT ìƒì„±
                company_cat = dataset.company_store['categorical'][company_indices]
                company_kjt = _build_batch_kjt_gpu(
                    torch.from_numpy(company_cat).long(),
                    dataset.schema.company.categorical
                )
                return {"dense": company_dense, "kjt": company_kjt}
            
            # ë³‘ë ¬ ì‹¤í–‰
            future_notice = executor.submit(process_notice)
            future_company = executor.submit(process_company)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            notice_result = future_notice.result()
            company_result = future_company.result()
        
        return {
            "notice": notice_result,
            "company": company_result
        }
    
    return collate_fn_gpu


def create_lightweight_collate_fn():
    """
    Lightweight collate function - ì¸ë±ìŠ¤ ì¶”ì¶œë§Œ ë‹´ë‹¹
    AsyncBatchPreprocessorì™€ í•¨ê»˜ ì‚¬ìš©
    """
    def lightweight_collate_fn(batch: List[Dict]) -> List[Dict]:
        # ë‹¨ìˆœížˆ ë°°ì¹˜ ì•„ì´í…œë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        # ë¬´ê±°ìš´ ì „ì²˜ë¦¬ëŠ” AsyncBatchPreprocessorì—ì„œ ë‹´ë‹¹
        return batch
    
    return lightweight_collate_fn


def create_collate_fn(dataset: 'UnifiedBidDataset'):
    """GPU ìµœì í™” collate í•¨ìˆ˜ - load_all_features=True, streaming=True ì „ìš©"""
    from concurrent.futures import ThreadPoolExecutor
    
    def collate_fn_gpu_optimized(batch: List[Dict]) -> Dict[str, Dict[str, torch.Tensor]]:
        # ë°°ì¹˜ì—ì„œ ì¸ë±ìŠ¤ë“¤ ì¶”ì¶œ
        notice_indices = [item["notice_idx"] for item in batch]
        company_indices = [item["company_idx"] for item in batch]
        
        # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ noticeì™€ company ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=2) as executor:
            # Notice ì²˜ë¦¬ í•¨ìˆ˜ (GPU ìµœì í™”)
            def process_notice():
                # Dense ë°ì´í„°: CPUì—ì„œ ì²˜ë¦¬ í›„ ë‚˜ì¤‘ì— GPU ì´ì „
                notice_dense = torch.from_numpy(
                    dataset.notice_store['dense_projected'][notice_indices]
                ).float()
                
                # Categorical ë°ì´í„°: CPUì—ì„œ KJT ìƒì„± (pin_memory í˜¸í™˜)
                notice_cat = dataset.notice_store['categorical'][notice_indices]
                notice_kjt = _build_batch_kjt(
                    torch.from_numpy(notice_cat).long(),
                    dataset.schema.notice.categorical
                )
                return {"dense": notice_dense, "kjt": notice_kjt}
            
            # Company ì²˜ë¦¬ í•¨ìˆ˜ (GPU ìµœì í™”)
            def process_company():
                # Dense ë°ì´í„°: CPUì—ì„œ ì²˜ë¦¬ í›„ ë‚˜ì¤‘ì— GPU ì´ì „  
                company_dense = torch.from_numpy(
                    dataset.company_store['dense_projected'][company_indices]
                ).float()
                
                # Categorical ë°ì´í„°: CPUì—ì„œ KJT ìƒì„± (pin_memory í˜¸í™˜)
                company_cat = dataset.company_store['categorical'][company_indices]
                company_kjt = _build_batch_kjt(
                    torch.from_numpy(company_cat).long(),
                    dataset.schema.company.categorical
                )
                return {"dense": company_dense, "kjt": company_kjt}
            
            # ë³‘ë ¬ ì‹¤í–‰
            future_notice = executor.submit(process_notice)
            future_company = executor.submit(process_company)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            notice_result = future_notice.result()
            company_result = future_company.result()
        
        return {
            "notice": notice_result,
            "company": company_result
        }
    
    return collate_fn_gpu_optimized


def create_async_optimized_dataloaders(
    db_engine,
    schema,
    batch_size: int = 32,
    limit: Optional[int] = None,
    test_split: float = 0.1,
    shuffle_seed: int = 42,
    pin_memory: bool = True,
    streaming: bool = True,
    chunk_size: int = 1000,
    load_all_features: bool = True,
    feature_chunksize: int = 5000,
    feature_limit: Optional[int] = None,
    use_preprocessor: bool = True
) -> Tuple[DataLoader, DataLoader]:
    """
    AsyncBatchPreprocessorë¥¼ ì‚¬ìš©í•˜ëŠ” ìµœì í™”ëœ DataLoader
    ê¸°ì¡´ create_unified_bid_dataloaders_gpuë¥¼ ëŒ€ì²´
    """
    from sqlalchemy.engine import Engine
    
    # ê¸°ì¡´ê³¼ ë™ì¼í•œ ë°ì´í„° ì¤€ë¹„ ë¡œì§
    shared_stores = None
    if load_all_features:
        if use_preprocessor and streaming:
            print("FeaturePreprocessorë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ì²˜ ì „ì²˜ë¦¬ ì¤‘...")
            from src.torchrec_preprocess.feature_preprocessor import FeaturePreprocessor
            
            preprocessor = FeaturePreprocessor(
                schema=schema,
                device='cuda:0' if torch.cuda.is_available() else 'cpu',
                num_proj_dim=128,
                text_proj_dim=128,
                batch_size=1024
            )
            
            preprocessed_stores = preprocessor.preprocess_all(
                db_engine=db_engine,
                feature_chunksize=feature_chunksize,
                feature_limit=feature_limit,
                show_progress=True
            )
            
            shared_stores = {
                'preprocessed': preprocessed_stores,
                'notice': preprocessed_stores['notice'],
                'company': preprocessed_stores['company']
            }
            print("Pre-projection ì™„ë£Œ!")
    
    # ë°ì´í„°ì…‹ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
    train_dataset = UnifiedBidDataset(
        db_engine=db_engine, schema=schema, limit=limit, is_train=True, 
        test_split=test_split, shuffle_seed=shuffle_seed, streaming=streaming, 
        chunk_size=chunk_size, load_all_features=load_all_features,
        feature_chunksize=feature_chunksize, feature_limit=feature_limit,
        shared_feature_stores=shared_stores,
    )
    
    test_dataset = UnifiedBidDataset(
        db_engine=db_engine, schema=schema, limit=limit, is_train=False, 
        test_split=test_split, shuffle_seed=shuffle_seed, streaming=streaming, 
        chunk_size=chunk_size, load_all_features=load_all_features,
        feature_chunksize=feature_chunksize, feature_limit=feature_limit,
        shared_feature_stores=shared_stores,
    )
    
    # Lightweight collate í•¨ìˆ˜ ì‚¬ìš©
    lightweight_collate_fn = create_lightweight_collate_fn()
    
    # DataLoader (lightweight collate í•¨ìˆ˜ ì‚¬ìš©)
    train_loader = DataLoader(
        dataset=train_dataset,
        batch_size=batch_size,
        shuffle=False,
        collate_fn=lightweight_collate_fn,
        num_workers=0,
        pin_memory=False  # AsyncBatchPreprocessorì—ì„œ pin_memory ì²˜ë¦¬
    )
    
    test_loader = None
    if test_dataset is not None:
        test_loader = DataLoader(
            dataset=test_dataset,
            batch_size=batch_size,
            shuffle=False,
            collate_fn=lightweight_collate_fn,
            num_workers=0,
            pin_memory=False
        )
    
    return train_loader, test_loader


# Helper í•¨ìˆ˜ë“¤
def _build_batch_kjt_original(categorical_data: torch.Tensor, categorical_keys: List[str]) -> 'KeyedJaggedTensor':
    """ë°°ì¹˜ìš© KJT ìƒì„± (ì›ë³¸ ë°±ì—…)"""
    from torchrec import KeyedJaggedTensor
    
    batch_size, num_features = categorical_data.shape
    values_list = []
    lengths_list = []
    
    for i in range(num_features):
        feature_values = categorical_data[:, i]
        lengths = torch.ones(batch_size, dtype=torch.long)
        values_list.append(feature_values)
        lengths_list.append(lengths)
    
    all_values = torch.cat(values_list)
    all_lengths = torch.cat(lengths_list)
    
    return KeyedJaggedTensor.from_lengths_sync(
        keys=categorical_keys,
        values=all_values,
        lengths=all_lengths
    )


def _build_batch_kjt_gpu(categorical_data: torch.Tensor, categorical_keys: List[str]) -> 'KeyedJaggedTensor':
    """GPU ê¸°ë°˜ ë°°ì¹˜ìš© KJT ìƒì„± (ìµœì í™” ë²„ì „)"""
    from torchrec import KeyedJaggedTensor
    
    # GPUë¡œ ì´ì „
    if categorical_data.device.type != 'cuda':
        categorical_data = categorical_data.cuda()
    
    batch_size, num_features = categorical_data.shape
    
    # GPUì—ì„œ ë©”ëª¨ë¦¬ í• ë‹¹ ë° reshape
    all_values = categorical_data.flatten()
    all_lengths = torch.ones(batch_size * num_features, dtype=torch.long, device=categorical_data.device)
    
    return KeyedJaggedTensor.from_lengths_sync(
        keys=categorical_keys,
        values=all_values,
        lengths=all_lengths
    )


def _build_batch_kjt(categorical_data: torch.Tensor, categorical_keys: List[str]) -> 'KeyedJaggedTensor':
    """ë°°ì¹˜ìš© KJT ìƒì„± (CPU ë²„ì „ - í˜¸í™˜ì„± ìœ ì§€)"""
    from torchrec import KeyedJaggedTensor
    
    batch_size, num_features = categorical_data.shape
    
    # ìµœì í™”: í•œ ë²ˆì— ë©”ëª¨ë¦¬ í• ë‹¹ ë° reshape
    all_values = categorical_data.flatten()
    all_lengths = torch.ones(batch_size * num_features, dtype=torch.long)
    
    return KeyedJaggedTensor.from_lengths_sync(
        keys=categorical_keys,
        values=all_values,
        lengths=all_lengths
    )


def _build_single_kjt(categorical_data: torch.Tensor, categorical_keys: List[str]) -> 'KeyedJaggedTensor':
    """ë‹¨ì¼ ìƒ˜í”Œìš© KJT ìƒì„±"""
    from torchrec import KeyedJaggedTensor
    
    values = categorical_data.flatten()
    lengths = torch.ones(len(categorical_keys), dtype=torch.long)
    
    return KeyedJaggedTensor.from_lengths_sync(
        keys=categorical_keys,
        values=values,
        lengths=lengths
    )


def _combine_kjts(kjt_list: List['KeyedJaggedTensor']) -> 'KeyedJaggedTensor':
    """KJT ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ê²°í•©"""
    from torchrec import KeyedJaggedTensor
    
    if not kjt_list:
        raise ValueError("Empty KJT list")
    
    keys = kjt_list[0].keys()
    values_list = [kjt.values() for kjt in kjt_list]
    lengths_list = [kjt.lengths() for kjt in kjt_list]
    
    combined_values = torch.cat(values_list)
    combined_lengths = torch.cat(lengths_list)
    
    return KeyedJaggedTensor.from_lengths_sync(
        keys=keys,
        values=combined_values,
        lengths=combined_lengths
    )



def create_unified_bid_dataloaders_gpu(
    db_engine: Engine,
    schema: TorchRecSchema,
    batch_size: int = 32,
    limit: Optional[int] = None,
    test_split: float = 0.1,
    shuffle_seed: int = 42,
    pin_memory: bool = False,  # GPU ë²„ì „ì—ì„œëŠ” False
    streaming: bool = False,
    chunk_size: int = 1000,
    load_all_features: bool = True,
    feature_chunksize: int = 5000,
    feature_limit: Optional[int] = None,
    use_preprocessor: bool = True
) -> Tuple[DataLoader, DataLoader]:
    """GPU ìµœì í™” DataLoader (ì˜µì…˜2: pin_memory=False + GPU ì²˜ë¦¬)"""
    
    # ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•œ ë°ì´í„° ì¤€ë¹„
    shared_stores = None
    if load_all_features:
        if use_preprocessor and streaming:
            print("FeaturePreprocessorë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ì²˜ ì „ì²˜ë¦¬ ì¤‘...")
            from src.torchrec_preprocess.feature_preprocessor import FeaturePreprocessor
            
            preprocessor = FeaturePreprocessor(
                schema=schema,
                device='cuda:0' if torch.cuda.is_available() else 'cpu',
                num_proj_dim=128,
                text_proj_dim=128,
                batch_size=1024
            )
            
            preprocessed_stores = preprocessor.preprocess_all(
                db_engine=db_engine,
                feature_chunksize=feature_chunksize,
                feature_limit=feature_limit,
                show_progress=True
            )
            
            shared_stores = {
                'preprocessed': preprocessed_stores,
                'notice': preprocessed_stores['notice'],
                'company': preprocessed_stores['company']
            }
            print("Pre-projection ì™„ë£Œ!")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = UnifiedBidDataset(
        db_engine=db_engine, schema=schema, limit=limit, is_train=True, 
        test_split=test_split, shuffle_seed=shuffle_seed, streaming=streaming, 
        chunk_size=chunk_size, load_all_features=load_all_features,
        feature_chunksize=feature_chunksize, feature_limit=feature_limit,
        shared_feature_stores=shared_stores,
    )
    
    test_dataset = UnifiedBidDataset(
        db_engine=db_engine, schema=schema, limit=limit, is_train=False, 
        test_split=test_split, shuffle_seed=shuffle_seed, streaming=streaming, 
        chunk_size=chunk_size, load_all_features=load_all_features,
        feature_chunksize=feature_chunksize, feature_limit=feature_limit,
        shared_feature_stores=shared_stores,
    )
    
    # GPU collate í•¨ìˆ˜ ì‚¬ìš©
    train_collate_fn = create_collate_fn_gpu(train_dataset)
    
    # DataLoader (pin_memory=False í•„ìˆ˜)
    train_loader = DataLoader(
        dataset=train_dataset,
        batch_size=batch_size,
        shuffle=False,
        collate_fn=train_collate_fn,
        num_workers=0,
        pin_memory=False  # GPU ë²„ì „ì—ì„œëŠ” False
    )
    
    test_loader = None
    if test_dataset is not None:
        test_collate_fn = create_collate_fn_gpu(test_dataset)
        test_loader = DataLoader(
            dataset=test_dataset,
            batch_size=batch_size,
            shuffle=False,
            collate_fn=test_collate_fn,
            num_workers=0,
            pin_memory=False  # GPU ë²„ì „ì—ì„œëŠ” False
        )
    
    return train_loader, test_loader


def create_unified_bid_dataloaders(
    db_engine: Engine,
    schema: TorchRecSchema,
    batch_size: int = 32,
    limit: Optional[int] = None,
    test_split: float = 0.1,
    shuffle_seed: int = 42,
    num_workers: int = 4,  # num_workers ì¶”ê°€
    pin_memory: bool = False,
    prefetch_factor: int = 2,  # prefetch_factor ì¶”ê°€
    persistent_workers: bool = False,  # persistent_workers ì¶”ê°€
    streaming: bool = False,
    chunk_size: int = 1000,
    load_all_features: bool = True,
    feature_chunksize: int = 5000,
    feature_limit: Optional[int] = None,
    use_preprocessor: bool = True,  # Pre-projection ì‚¬ìš© ì—¬ë¶€
    test_mode: bool = False,        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ í”Œëž˜ê·¸
    pair_limit: Optional[int] = None,  # í…ŒìŠ¤íŠ¸ ì‹œ pair ì œí•œ

) -> Tuple[DataLoader, DataLoader]:
    """
    í†µí•© DataLoader ìƒì„±

    Args:
        streaming: Trueë©´ pair ìŠ¤íŠ¸ë¦¬ë°
        load_all_features: Falseë©´ ì„ íƒì  í”¼ì²˜ ë¡œë”©
        chunk_size: ìŠ¤íŠ¸ë¦¬ë° ì‹œ ì²­í¬ í¬ê¸°
        feature_chunksize: í”¼ì²˜ ë¡œë”© ì‹œ ì²­í¬ í¬ê¸°
        feature_limit: í”¼ì²˜ ë¡œë”© ì‹œ ì œí•œ
        use_preprocessor: Trueë©´ FeaturePreprocessorë¥¼ ì‚¬ìš©í•˜ì—¬ pre-projection
        test_mode: Trueë©´ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì„ íƒì  ë¡œë”© ëª¨ë“œ
        pair_limit: test_mode=Trueì¼ ë•Œ ì‚¬ìš©í•  pair ìˆ˜ ì œí•œ
    """

    # Test Mode: ì„ íƒì  í”¼ì²˜ ë¡œë”©
    if test_mode:
        print(f"ðŸ§ª Test Mode í™œì„±í™”: pair_limit={pair_limit}")
        return _create_test_mode_dataloaders(
            db_engine=db_engine,
            schema=schema,
            batch_size=batch_size,
            pair_limit=pair_limit,
            test_split=test_split,
            shuffle_seed=shuffle_seed,
            num_workers=num_workers,
            pin_memory=pin_memory,
            prefetch_factor=prefetch_factor,
            persistent_workers=persistent_workers,
            use_preprocessor=use_preprocessor
        )

    shared_stores = None
    if load_all_features:
        if use_preprocessor and streaming:  # streaming=True, load_all_features=Trueì—ì„œë§Œ ì‚¬ìš©
            print("FeaturePreprocessorë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ì²˜ ì „ì²˜ë¦¬ ì¤‘...")
            
            # FeaturePreprocessorë¡œ ì „ì²´ í”¼ì²˜ ì „ì²˜ë¦¬
            preprocessor = FeaturePreprocessor(
                schema=schema,
                device='cuda:0' if torch.cuda.is_available() else 'cpu',
                num_proj_dim=128,
                text_proj_dim=128,
                batch_size=1024
            )
            
            preprocessed_stores = preprocessor.preprocess_all(
                db_engine=db_engine,
                feature_chunksize=feature_chunksize,
                feature_limit=feature_limit,
                show_progress=True
            )
            
            # ID ë§¤í•‘ ìƒì„±
            notice_id_to_idx, company_id_to_idx = preprocessor.build_id_mappings(preprocessed_stores)
            
            shared_stores = {
                'preprocessed': preprocessed_stores,
                'notice': preprocessed_stores['notice'],
                'company': preprocessed_stores['company']
            }
            print("Pre-projection ì™„ë£Œ!")
        else:
            # ê¸°ì¡´ ë°©ì‹ (raw stores)
            print("ê³µìœ  í”¼ì²˜ ë°ì´í„° ë¡œë”© ì¤‘...")
            
            notice_store = build_feature_store(
                db_engine, schema.notice, 
                chunksize=feature_chunksize, 
                limit=feature_limit, 
                show_progress=True
            )
            
            company_store = build_feature_store(
                db_engine, schema.company, 
                chunksize=feature_chunksize, 
                limit=feature_limit, 
                show_progress=True
            )
            
            shared_stores = {
                'notice': notice_store,
                'company': company_store
            }
            print("ê³µìœ  í”¼ì²˜ ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
    
    # ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ëª¨ë“œ: DB config ë¶ˆí•„ìš”
    
    train_dataset = UnifiedBidDataset(
        db_engine=db_engine, schema=schema, limit=limit,
        test_split=test_split, is_train=True, shuffle_seed=shuffle_seed,
        streaming=streaming, chunk_size=chunk_size, load_all_features=load_all_features,
        feature_chunksize=feature_chunksize, feature_limit=feature_limit,
        shared_feature_stores=shared_stores,
    )
    
    test_dataset = None
    if test_split > 0:
        test_dataset = UnifiedBidDataset(
            db_engine=db_engine, schema=schema, limit=limit,
            test_split=test_split, is_train=False, shuffle_seed=shuffle_seed,
            streaming=streaming, chunk_size=chunk_size, load_all_features=load_all_features,
            feature_chunksize=feature_chunksize, feature_limit=feature_limit,
            shared_feature_stores=shared_stores,
            )
    
    # ë°ì´í„°ì…‹ì— ë§žëŠ” collate í•¨ìˆ˜ ìƒì„±
    train_collate_fn = create_collate_fn(train_dataset)
    
    # DataLoader íŒŒë¼ë¯¸í„° (ë©€í‹°í”„ë¡œì„¸ìŠ¤ ì§€ì›)
    train_loader = DataLoader(
        dataset=train_dataset,
        batch_size=batch_size,
        shuffle=False,
        collate_fn=train_collate_fn,
        num_workers=num_workers,
        pin_memory=pin_memory,
        prefetch_factor=prefetch_factor if num_workers > 0 else None,
        persistent_workers=persistent_workers if num_workers > 0 else False
    )       
    
    test_loader = None
    if test_dataset is not None:
        test_collate_fn = create_collate_fn(test_dataset)
        
        # Test DataLoader (ë©€í‹°í”„ë¡œì„¸ìŠ¤ ì§€ì›)
        test_loader = DataLoader(
            dataset=test_dataset,
            batch_size=batch_size,
            shuffle=False,
            collate_fn=test_collate_fn,
            num_workers=num_workers,
            pin_memory=pin_memory,
            prefetch_factor=prefetch_factor if num_workers > 0 else None,
            persistent_workers=persistent_workers if num_workers > 0 else False
        )
    
    return train_loader, test_loader



if __name__ == "__main__":
    from data.database_connector import DatabaseConnector
    from src.torchrec_preprocess.schema import build_torchrec_schema_from_meta
    
    db = DatabaseConnector()
    engine = db.engine
    
    config = {
        "notice_table": "notice", "company_table": "company", 
        "pair_table": "bid_two_tower",
        "pair_notice_id_cols": ["bidntceno", "bidntceord"],
        "pair_company_id_cols": ["bizno"],
        "metadata_path": "meta/metadata.csv"
    }
    schema = build_torchrec_schema_from_meta(**config)
    
    print("=== ì™„ì „ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í…ŒìŠ¤íŠ¸ (ê¶Œìž¥) ===")
    train_loader, test_loader = create_unified_bid_dataloaders(
        db_engine=engine, schema=schema, batch_size=16,
        limit=10000, test_split=0.2, 
        streaming=True, load_all_features=False, chunk_size=500
    )
    
    print(f"Train batches: {len(train_loader)}")
    print(f"Test batches: {len(test_loader) if test_loader else 'None'}")

    for batch_idx, batch in enumerate(train_loader):
        print(f"Batch {batch_idx}: Notice {batch['notice']['dense'].shape}, Company {batch['company']['dense'].shape}")
        if batch_idx >= 2:
            break


def _create_test_mode_dataloaders(
    db_engine: Engine,
    schema: TorchRecSchema,
    batch_size: int,
    pair_limit: Optional[int],
    test_split: float,
    shuffle_seed: int,
    num_workers: int,
    pin_memory: bool,
    prefetch_factor: int,
    persistent_workers: bool,
    use_preprocessor: bool
) -> Tuple[DataLoader, DataLoader]:
    """
    Test Modeìš© DataLoader ìƒì„± - ì‹¤ì œ pairì— í•´ë‹¹í•˜ëŠ” í”¼ì²˜ë§Œ ì„ íƒì  ë¡œë”©

    í•µì‹¬: pair â†’ ID ì¶”ì¶œ â†’ í•´ë‹¹ ID í”¼ì²˜ë§Œ ë¡œë”© â†’ 100% ë§¤ì¹­ ë³´ìž¥
    """

    # 1. ì œí•œëœ pair ë¡œë”©
    print("ðŸ“Š ì œí•œëœ pair ë°ì´í„° ë¡œë”© ì¤‘...")
    pair_query = f"""
    SELECT bidntceno, bidntceord, bizno, id
    FROM bid_two_tower
    """
    if pair_limit:
        pair_query += f" LIMIT {pair_limit}"

    pairs_df = pd.read_sql(pair_query, db_engine)
    print(f"   ë¡œë”©ëœ pair ìˆ˜: {len(pairs_df):,}")

    # 2. ì‹¤ì œ pair ID ì¶”ì¶œ
    notice_ids = set(zip(pairs_df['bidntceno'], pairs_df['bidntceord']))
    company_ids = set(pairs_df['bizno'].astype(str))

    print(f"   Notice ID ìˆ˜: {len(notice_ids):,}")
    print(f"   Company ID ìˆ˜: {len(company_ids):,}")

    # 3. ì„ íƒì  í”¼ì²˜ ë¡œë”© (100% ë§¤ì¹­ ë³´ìž¥)
    print("ðŸŽ¯ ì„ íƒì  í”¼ì²˜ ë¡œë”© ì¤‘...")
    print(f"   Notice ID {len(notice_ids):,}ê°œë§Œ DBì—ì„œ ì§ì ‘ ë¡œë”©...")
    print(f"   Company ID {len(company_ids):,}ê°œë§Œ DBì—ì„œ ì§ì ‘ ë¡œë”©...")

    # SQL WHERE ì¡°ê±´ì ˆë¡œ í•„ìš”í•œ IDë§Œ ì§ì ‘ ë¡œë”©
    notice_store = _load_features_for_test_mode(
        db_engine, schema.notice, notice_ids, "notice", show_progress=True
    )
    company_store = _load_features_for_test_mode(
        db_engine, schema.company, company_ids, "company", show_progress=True
    )

    # 4. ID ë§¤í•‘ ìƒì„± (ì„ íƒëœ IDë§Œ)
    notice_id_to_idx = {id_tuple: idx for idx, id_tuple in enumerate(notice_ids)}
    company_id_to_idx = {str(id_val): idx for idx, id_val in enumerate(company_ids)}

    print(f"âœ… ë§¤ì¹­ ë³´ìž¥: Notice {len(notice_id_to_idx)}, Company {len(company_id_to_idx)}")

    # 5. Train/Test ë¶„í• 
    train_pairs, test_pairs = None, None
    if test_split > 0:
        from sklearn.model_selection import train_test_split
        train_pairs, test_pairs = train_test_split(
            pairs_df, test_size=test_split, random_state=shuffle_seed
        )
    else:
        train_pairs = pairs_df

    # 6. ê³µìœ  ìŠ¤í† ì–´ ìƒì„± (pairs í¬í•¨)
    shared_stores = {
        'notice': notice_store,
        'company': company_store,
        'pairs_data': {
            'train_pairs': train_pairs,
            'test_pairs': test_pairs,
            'notice_id_to_idx': notice_id_to_idx,
            'company_id_to_idx': company_id_to_idx
        }
    }

    # 7. Dataset ìƒì„± (ì¼ë‹¨ ì „ì²´ ë°ì´í„°ë¡œ ê¸°ë³¸ ìƒì„±)
    # Test Modeì—ì„œëŠ” ID ë§¤í•‘ë§Œ ë®ì–´ì”Œìš°ê¸°
    train_dataset = UnifiedBidDataset(
        db_engine=db_engine,
        schema=schema,
        limit=pair_limit,  # pair_limit ì‚¬ìš©
        test_split=test_split,
        is_train=True,
        streaming=False,  # Test modeëŠ” ì •ì  ë¡œë”©
        chunk_size=1000,
        load_all_features=True,
        shared_feature_stores=shared_stores,
    )

    test_dataset = None
    if test_split > 0:
        test_dataset = UnifiedBidDataset(
            db_engine=db_engine,
            schema=schema,
            limit=pair_limit,
            test_split=test_split,
            is_train=False,
            streaming=False,
            chunk_size=1000,
            load_all_features=True,
            shared_feature_stores=shared_stores,
        )

    # 8. Collate í•¨ìˆ˜ ì„ íƒ
    train_collate_fn = create_collate_fn(train_dataset)

    # 9. DataLoader ìƒì„±
    train_loader = DataLoader(
        dataset=train_dataset,
        batch_size=batch_size,
        shuffle=True,  # Test modeì—ì„œë„ ì…”í”Œ í—ˆìš©
        collate_fn=train_collate_fn,
        num_workers=num_workers,
        pin_memory=pin_memory,
        prefetch_factor=prefetch_factor if num_workers > 0 else None,
        persistent_workers=persistent_workers if num_workers > 0 else False
    )

    test_loader = None
    if test_dataset is not None:
        test_collate_fn = create_collate_fn(test_dataset)
        test_loader = DataLoader(
            dataset=test_dataset,
            batch_size=batch_size,
            shuffle=False,
            collate_fn=test_collate_fn,
            num_workers=num_workers,
            pin_memory=pin_memory,
            prefetch_factor=prefetch_factor if num_workers > 0 else None,
            persistent_workers=persistent_workers if num_workers > 0 else False
        )

    print(f"ðŸŽ¯ Test Mode DataLoader ì™„ì„±!")
    print(f"   Train ë°°ì¹˜: {len(train_loader)}")
    print(f"   Test ë°°ì¹˜: {len(test_loader) if test_loader else 0}")

    return train_loader, test_loader


def _load_features_for_test_mode(
    db_engine: Engine,
    schema_part,  # schema.notice ë˜ëŠ” schema.company
    target_ids: set,
    table_type: str,  # "notice" ë˜ëŠ” "company"
    show_progress: bool = False
) -> Dict:
    """Test Modeìš© ì„ íƒì  í”¼ì²˜ ë¡œë”© (SQL WHERE ì¡°ê±´ì ˆ ì‚¬ìš©)"""

    id_list = list(target_ids)
    print(f"Loading {table_type}: {len(id_list):,}ê°œ")

    if table_type == "notice":
        # Notice ID ì¡°ê±´ ìƒì„± (tuples of bidntceno, bidntceord)
        conditions = []
        for bidntceno, bidntceord in id_list:
            conditions.append(f"(bidntceno='{bidntceno}' AND bidntceord::integer={int(bidntceord)})")
        where_condition = " OR ".join(conditions)

    elif table_type == "company":
        # Company ID ì¡°ê±´ ìƒì„± (bizno IN clause)
        quoted_ids = [f"'{cid}'" for cid in id_list]
        where_condition = "bizno IN (" + ",".join(quoted_ids) + ")"

    else:
        raise ValueError(f"Unknown table_type: {table_type}")

    # SQL WHERE ì¡°ê±´ìœ¼ë¡œ í”¼ì²˜ ë¡œë”©
    store = build_feature_store_with_condition(
        db_engine, schema_part, where_condition=where_condition, show_progress=show_progress
    )

    # ë””ë²„ê¹…: store ë‚´ìš© í™•ì¸
    available_keys = list(store.keys())
    print(f"âœ… {table_type.capitalize()} í”¼ì²˜ ë¡œë”© ì™„ë£Œ")
    print(f"   Available keys: {available_keys}")
    for key in available_keys:
        if hasattr(store[key], '__len__'):
            print(f"   {key}: {len(store[key])} items")

    return store


def _load_features_for_test_mode_with_preprocessor(
    db_engine: Engine,
    schema: TorchRecSchema,
    notice_ids: set,
    company_ids: set
) -> Tuple[Dict, Dict]:
    """Test Modeìš© Preprocessor í”¼ì²˜ ë¡œë”© (ì„ íƒëœ IDë§Œ)"""

    from src.torchrec_preprocess.feature_preprocessor import FeaturePreprocessor

    # ID í•„í„° ê¸°ë°˜ Preprocessor ì‹¤í–‰
    preprocessor = FeaturePreprocessor(
        schema=schema,
        device='cuda:0' if torch.cuda.is_available() else 'cpu',
        num_proj_dim=128,
        text_proj_dim=128,
        batch_size=1024
    )

    # ì„ íƒì  ì „ì²˜ë¦¬ (í•´ë‹¹ IDë§Œ)
    preprocessed_stores = preprocessor.preprocess_selective(
        db_engine=db_engine,
        notice_id_filter=notice_ids,
        company_id_filter=company_ids,
        show_progress=True
    )

    return preprocessed_stores['notice'], preprocessed_stores['company']


def _project_raw_features(self):
    """Test mode: raw í”¼ì²˜ ë°ì´í„°ë¥¼ projectioní•˜ì—¬ dense_projected ìƒì„±"""
    import torch
    import numpy as np

    # ë””ë²„ê¹…: text ë°ì´í„° êµ¬ì¡° í™•ì¸
    print(f"    Notice text type: {type(self.notice_store['text'])}")
    print(f"    Company text type: {type(self.company_store['text'])}")

    if isinstance(self.notice_store['text'], dict):
        print(f"    Notice text keys: {list(self.notice_store['text'].keys())}")
    if isinstance(self.company_store['text'], dict):
        print(f"    Company text keys: {list(self.company_store['text'].keys())}")

    # Notice projection
    notice_numeric = torch.from_numpy(self.notice_store['numeric']).float()

    # text ë°ì´í„° ì²˜ë¦¬ - FeatureProjectorëŠ” dictë¥¼ ê¸°ëŒ€í•¨
    if isinstance(self.notice_store['text'], dict):
        notice_text_dict = {
            key: torch.from_numpy(val).float()
            for key, val in self.notice_store['text'].items()
        }
    else:
        # textê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ dict
        notice_text_dict = {}

    with torch.no_grad():
        notice_dense_proj, notice_text_proj = self.notice_projector(notice_numeric, notice_text_dict)
        # ìµœì¢… projection ê²°í•© (dense + text)
        if notice_text_proj:
            # text projectionì´ ìžˆìœ¼ë©´ concatenate
            text_values = list(notice_text_proj.values())
            combined_text = torch.cat(text_values, dim=1) if text_values else torch.zeros(notice_dense_proj.size(0), 0)
            notice_projected = torch.cat([notice_dense_proj, combined_text], dim=1)
        else:
            notice_projected = notice_dense_proj

    # Company projection
    company_numeric = torch.from_numpy(self.company_store['numeric']).float()

    # Company text ë°ì´í„° ì²˜ë¦¬ - FeatureProjectorëŠ” dictë¥¼ ê¸°ëŒ€í•¨
    if isinstance(self.company_store['text'], dict):
        company_text_dict = {
            key: torch.from_numpy(val).float()
            for key, val in self.company_store['text'].items()
        }
    else:
        # textê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ dict (CompanyëŠ” Noneì¸ ê²½ìš°ê°€ ë§ŽìŒ)
        company_text_dict = {}

    with torch.no_grad():
        company_dense_proj, company_text_proj = self.company_projector(company_numeric, company_text_dict)
        # ìµœì¢… projection ê²°í•© (dense + text)
        if company_text_proj:
            # text projectionì´ ìžˆìœ¼ë©´ concatenate
            text_values = list(company_text_proj.values())
            combined_text = torch.cat(text_values, dim=1) if text_values else torch.zeros(company_dense_proj.size(0), 0)
            company_projected = torch.cat([company_dense_proj, combined_text], dim=1)
        else:
            company_projected = company_dense_proj

    # dense_projected í‚¤ ì¶”ê°€
    self.notice_store['dense_projected'] = notice_projected.numpy()
    self.company_store['dense_projected'] = company_projected.numpy()

    print(f"    Notice projection: {notice_projected.shape}")
    print(f"    Company projection: {company_projected.shape}")


# UnifiedBidDataset í´ëž˜ìŠ¤ì— ë©”ì„œë“œ ë°”ì¸ë”©
UnifiedBidDataset._project_raw_features = _project_raw_features