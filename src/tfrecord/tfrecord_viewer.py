#!/usr/bin/env python3
"""
TFRecord íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•˜ëŠ” ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
"""

import tensorflow as tf
import json
from typing import Dict, Any, Optional
import os



def parse_tfrecord_example(example_proto):
    """TFRecord Exampleì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
    # Feature ì •ì˜ (ë™ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë¹„ì›Œë‘ )
    feature_description = {}
    
    # Example íŒŒì‹±
    example = tf.train.Example()
    example.ParseFromString(example_proto.numpy())
    
    result = {}
    for feature_name, feature in example.features.feature.items():
        # Feature íƒ€ì…ì— ë”°ë¼ ê°’ ì¶”ì¶œ
        if feature.HasField('int64_list'):
            values = list(feature.int64_list.value)
            result[feature_name] = values[0] if len(values) == 1 else values
        elif feature.HasField('float_list'):
            values = list(feature.float_list.value)
            result[feature_name] = values[0] if len(values) == 1 else values
        elif feature.HasField('bytes_list'):
            values = [v.decode('utf-8', errors='ignore') for v in feature.bytes_list.value]
            result[feature_name] = values[0] if len(values) == 1 else values
    
    return result

def inspect_tfrecord(file_path: str, max_records: int = 5, show_schema: bool = True):
    """
    TFRecord íŒŒì¼ì˜ ë‚´ìš©ì„ ê²€ì‚¬
    
    Args:
        file_path: TFRecord íŒŒì¼ ê²½ë¡œ
        max_records: ì¶œë ¥í•  ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜
        show_schema: ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶œë ¥ ì—¬ë¶€
    """
    print(f"ğŸ” TFRecord íŒŒì¼ ê²€ì‚¬: {file_path}")
    print("=" * 80)
    
    # ì••ì¶• ì—¬ë¶€ í™•ì¸
    compression = "GZIP" if file_path.endswith('.gz') else ""
    
    try:
        dataset = tf.data.TFRecordDataset(file_path, compression_type=compression)
        
        # ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘
        all_features = set()
        feature_types = {}
        total_count = 0
        
        records = []
        for raw_record in dataset.take(max_records + 100):  # ìŠ¤í‚¤ë§ˆ íŒŒì•…ì„ ìœ„í•´ ë” ë§ì´ ì½ê¸°
            try:
                parsed = parse_tfrecord_example(raw_record)
                total_count += 1
                
                # ì²˜ìŒ max_recordsê°œë§Œ ì €ì¥
                if len(records) < max_records:
                    records.append(parsed)
                
                # ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘
                for key, value in parsed.items():
                    all_features.add(key)
                    if key not in feature_types:
                        feature_types[key] = type(value).__name__
                        
            except Exception as e:
                print(f"âŒ ë ˆì½”ë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
        
        # ì „ì²´ ë ˆì½”ë“œ ìˆ˜ ê³„ì‚° (ë” ì •í™•í•˜ê²Œ)
        if total_count >= max_records + 100:
            total_count = sum(1 for _ in dataset)
        
        print(f"ğŸ“Š ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {total_count:,}")
        print(f"ğŸ“‹ ì´ {len(all_features)}ê°œ í”¼ì²˜")
        
        if show_schema:
            print("\nğŸ—‚ï¸  ìŠ¤í‚¤ë§ˆ ì •ë³´:")
            print("-" * 40)
            for feature in sorted(all_features):
                feature_type = feature_types.get(feature, 'unknown')
                print(f"  {feature:<30} {feature_type}")
        
        print(f"\nğŸ“„ ë ˆì½”ë“œ ìƒ˜í”Œ ({min(max_records, len(records))}ê°œ):")
        print("=" * 80)
        
        for i, record in enumerate(records):
            print(f"\nğŸ“ ë ˆì½”ë“œ #{i+1}:")
            print("-" * 40)
            for key, value in record.items():
                # ê°’ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                if isinstance(value, str) and len(value) > 100:
                    display_value = value[:100] + "..."
                elif isinstance(value, list) and len(value) > 10:
                    display_value = f"{value[:5]} ... (+{len(value)-5} more)"
                else:
                    display_value = value
                
                print(f"  {key:<25} : {display_value}")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

def search_records(file_path: str, search_key: str, search_value: Any, max_results: int = 10):
    """
    íŠ¹ì • ì¡°ê±´ì— ë§ëŠ” ë ˆì½”ë“œ ê²€ìƒ‰
    
    Args:
        file_path: TFRecord íŒŒì¼ ê²½ë¡œ
        search_key: ê²€ìƒ‰í•  í‚¤
        search_value: ê²€ìƒ‰í•  ê°’
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
    """
    print(f"ğŸ” ê²€ìƒ‰ ì¡°ê±´: {search_key} = {search_value}")
    print("=" * 80)
    
    compression = "GZIP" if file_path.endswith('.gz') else ""
    dataset = tf.data.TFRecordDataset(file_path, compression_type=compression)
    
    found_count = 0
    total_checked = 0
    
    for raw_record in dataset:
        try:
            parsed = parse_tfrecord_example(raw_record)
            total_checked += 1
            
            if search_key in parsed and parsed[search_key] == search_value:
                found_count += 1
                print(f"\nâœ… ë°œê²¬ëœ ë ˆì½”ë“œ #{found_count} (ì „ì²´ {total_checked}ë²ˆì§¸):")
                print("-" * 40)
                for key, value in parsed.items():
                    if isinstance(value, str) and len(value) > 100:
                        display_value = value[:100] + "..."
                    else:
                        display_value = value
                    print(f"  {key:<25} : {display_value}")
                
                if found_count >= max_results:
                    break
                    
        except Exception as e:
            continue
    
    print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {found_count}ê°œ ë°œê²¬ (ì´ {total_checked}ê°œ í™•ì¸)")
    

def count_tfrecords(pattern, compression=None):
    files = tf.io.gfile.glob(pattern) if "*" in pattern else [pattern]
    ds = tf.data.TFRecordDataset(
        files,
        compression_type=compression,           # "GZIP" ì‚¬ìš© ì¤‘ì´ë©´ ê¼­ ì§€ì •
        num_parallel_reads=tf.data.AUTOTUNE,
    )
    return ds.reduce(tf.constant(0, tf.int64), lambda x, _: x + 1).numpy()


if __name__ == "__main__":
    print("notices:",  count_tfrecords("output/tfrecord/notice_preprocessed.tfrecord.gz", compression="GZIP"))
    print("companies:",count_tfrecords("output/tfrecord/company_preprocessed.tfrecord.gz", compression="GZIP"))
    print("pairs:",    count_tfrecords("output/tfrecord/pairs.tfrecord.gz", compression="GZIP"))
    