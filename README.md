# Two-Tower Model for Bid Recommendation

ìž…ì°° ì¶”ì²œì„ ìœ„í•œ Two-Tower ëª¨ë¸ êµ¬í˜„ (PyTorch + TorchRec)

## ðŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

- **ëª©í‘œ**: ê³µê³ (Notice)ì™€ ê¸°ì—…(Company) ê°„ì˜ ìž…ì°° ë§¤ì¹­ì„ ìœ„í•œ ì¶”ì²œ ì‹œìŠ¤í…œ
- **ì•„í‚¤í…ì²˜**: Two-Tower Neural Network (Retrieval Model)
- **í”„ë ˆìž„ì›Œí¬**: PyTorch, TorchRec
- **ë°ì´í„°**: ê³µê³  í”¼ì²˜ + ê¸°ì—… í”¼ì²˜ + ìž…ì°° íŽ˜ì–´ ë°ì´í„°

## ðŸ— ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
Notice Tower                    Company Tower
    â†“                               â†“
Dense Features                  Dense Features
Categorical Features           Categorical Features
    â†“                               â†“
Feature Projection             Feature Projection
    â†“                               â†“
Hidden Layers [128, 64]        Hidden Layers [128, 64]
    â†“                               â†“
Embedding (64D)                Embedding (64D)
    â†“                               â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€> Cosine Similarity <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
                  Cross Entropy Loss
```

## ðŸš€ ì„±ëŠ¥ ìµœì í™” ì´ë ¥

### 1. ì´ˆê¸° êµ¬í˜„ (Baseline)
- **ì†ë„**: ~11 batch/s (ìˆœì°¨ ì²˜ë¦¬)
- **GPU í™œìš©ë¥ **: 40%
- **ë°©ì‹**: ë‹¨ìˆœ DataLoader + collate_fn

### 2. íŒŒì´í”„ë¼ì¸ ì‹œë„ë“¤

#### AsyncBatchPreprocessor (ì‹¤íŒ¨)
- ë¹„ë™ê¸° ì „ì²˜ë¦¬ ì‹œë„
- ê²°ê³¼: ê°€ì§œ íŒŒì´í”„ë¼ì¸, ì‹¤ì œ ì˜¤ë²„ëž© ì—†ìŒ

#### TrueOverlapPipeline (ì‹¤íŒ¨)
- ë³µìž¡í•œ ë©€í‹°ìŠ¤ë ˆë”© êµ¬ì¡°
- StreamingDataLoaderManager + BatchProcessorPool
- **ë¬¸ì œ**: ê³¼ë„í•œ ì˜¤ë²„í—¤ë“œë¡œ 4.63 it/së¡œ ëŠë ¤ì§ (5ë°° ê°ì†Œ!)
- **ì›ì¸**: Python GIL + ë¶ˆí•„ìš”í•œ ë™ê¸°í™”

### 3. í˜„ìž¬ ì†”ë£¨ì…˜ (ìˆœì°¨ ì²˜ë¦¬ + DataLoader ìµœì í™”)
- **ë°©ì‹**: ë‹¨ìˆœ ìˆœì°¨ ì²˜ë¦¬ë¡œ ë³µì›
- **ìµœì í™”**:
  - `num_workers`: 0 â†’ 12 (ë©€í‹°í”„ë¡œì„¸ìŠ¤ ë°ì´í„° ë¡œë”©)
  - `prefetch_factor`: 2 â†’ 4
  - `persistent_workers`: True
  - `pin_memory`: True
- **ëª©í‘œ**: 23+ it/s íšŒë³µ

## ðŸ“ ì£¼ìš” íŒŒì¼ êµ¬ì¡°

```
jodalroB-twoTower/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train.py                    # ë©”ì¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ towers/
â”‚   â”‚   â”œâ”€â”€ two_tower_train_task.py # Two-Tower ëª¨ë¸ ì •ì˜
â”‚   â”‚   â””â”€â”€ pairs/
â”‚   â”‚       â””â”€â”€ unified_bid_data_loader.py  # ë°ì´í„°ë¡œë”
â”‚   â”œâ”€â”€ torchrec_preprocess/
â”‚   â”‚   â”œâ”€â”€ feature_preprocessor.py # í”¼ì²˜ ì „ì²˜ë¦¬ (pre-projection)
â”‚   â”‚   â”œâ”€â”€ schema.py               # TorchRec ìŠ¤í‚¤ë§ˆ
â”‚   â”‚   â””â”€â”€ feature_store.py        # í”¼ì²˜ ìŠ¤í† ì–´
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ pipeline_wrapper.py     # (deprecated) ì´ˆê¸° íŒŒì´í”„ë¼ì¸
â”‚       â”œâ”€â”€ async_batch_preprocessor.py # (deprecated) ë¹„ë™ê¸° ì „ì²˜ë¦¬
â”‚       â””â”€â”€ true_overlap_pipeline.py    # (deprecated) ë³µìž¡í•œ íŒŒì´í”„ë¼ì¸
â””â”€â”€ data/
    â””â”€â”€ database_connector.py       # DB ì—°ê²°
```

## ðŸ”§ ì£¼ìš” ì„¤ì •

### ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
```python
- categorical_embedding_dim: 32
- tower_hidden_dims: [128, 64]
- final_embedding_dim: 64
- dropout_rate: 0.1
- learning_rate: 1e-3
- batch_size: 256
```

### ë°ì´í„° ì„¤ì •
```python
- chunk_size: 1,000,000  # ì²­í¬ ë‹¨ìœ„ ë¡œë”©
- feature_limit: 100,000  # í”¼ì²˜ ë°ì´í„° ì œí•œ
- test_split: 0.2
- num_workers: 12         # DataLoader ì›Œì»¤
```

## ðŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­

| êµ¬í˜„ | ì†ë„ (it/s) | GPU í™œìš©ë¥  | ë¹„ê³  |
|------|------------|-----------|------|
| Baseline | 23 | 40% | ìˆœì°¨ ì²˜ë¦¬ |
| AsyncBatchPreprocessor | ~23 | 40% | ê°€ì§œ íŒŒì´í”„ë¼ì¸ |
| TrueOverlapPipeline | 4.63 | <20% | ì˜¤ë²„í—¤ë“œ ê³¼ë‹¤ |
| **í˜„ìž¬ (ìµœì í™”)** | **ëª©í‘œ: 45+** | **ëª©í‘œ: 80%** | DataLoader ìµœì í™” |

## ðŸŽ¯ í•µì‹¬ êµí›ˆ

1. **ë³µìž¡í•œ ë³‘ë ¬í™”ê°€ í•­ìƒ ë‹µì€ ì•„ë‹ˆë‹¤**
   - Python GIL ì œì•½ ê³ ë ¤ í•„ìš”
   - ì˜¤ë²„í—¤ë“œ vs ì´ìµ ë¶„ì„ ì¤‘ìš”

2. **DataLoader ìžì²´ ìµœì í™”ê°€ íš¨ê³¼ì **
   - PyTorchì˜ ë‚´ìž¥ ë©€í‹°í”„ë¡œì„¸ì‹± í™œìš©
   - num_workers ì¡°ì •ì´ í•µì‹¬

3. **í”„ë¡œíŒŒì¼ë§ì˜ ì¤‘ìš”ì„±**
   - ì‹¤ì œ ë³‘ëª© ì§€ì  íŒŒì•… í•„ìˆ˜
   - ì¶”ì¸¡ì´ ì•„ë‹Œ ì¸¡ì • ê¸°ë°˜ ìµœì í™”

## ðŸš¦ ì‹¤í–‰ ë°©ë²•

```bash
# í•™ìŠµ ì‹¤í–‰
python scripts/train.py

# ì£¼ìš” ë¡œê·¸ í™•ì¸ í¬ì¸íŠ¸
- "Training (Sequential)" ì§„í–‰ë¥  ë°”ì˜ it/s
- ë°°ì¹˜ ì²˜ë¦¬ ì†ë„
- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
```

## ðŸ“ˆ ë‹¤ìŒ ë‹¨ê³„

1. **CUDA Stream í™œìš©**
   - GPU ì „ì†¡ê³¼ ì—°ì‚° ì˜¤ë²„ëž©
   - torch.cuda.Stream() í™œìš©

2. **Mixed Precision Training**
   - FP16/BF16 í™œìš©
   - ë©”ëª¨ë¦¬ ì ˆì•½ + ì†ë„ í–¥ìƒ

3. **Distributed Training**
   - ë©€í‹° GPU í™œìš©
   - DDP (DistributedDataParallel)

## ðŸ› ì•Œë ¤ì§„ ì´ìŠˆ

- streaming=True ëª¨ë“œì—ì„œ ì²­í¬ ë¡œë”© ì‹œ ê°„í—ì  ì§€ì—°
- ì²« ë²ˆì§¸ ì—í¬í¬ ì‹œìž‘ ì‹œ í”¼ì²˜ ë¡œë”©ìœ¼ë¡œ ì¸í•œ ì´ˆê¸° ì§€ì—°

## ðŸ“ ì°¸ê³  ìžë£Œ

- [PyTorch TorchRec Two Tower Example](https://github.com/pytorch/torchrec/blob/main/examples/retrieval/two_tower_train.py)
- [TorchRec Documentation](https://pytorch.org/torchrec/)

---

**Last Updated**: 2025-09-11  
**Status**: ì„±ëŠ¥ ìµœì í™” ì§„í–‰ ì¤‘ (ìˆœì°¨ ì²˜ë¦¬ + DataLoader ìµœì í™”)
