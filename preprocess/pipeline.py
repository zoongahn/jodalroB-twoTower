# pipeline.py
from typing import Tuple, List

from data.database_connector import DatabaseConnector
from data.query_helper import QueryHelper
import pandas as pd

from preprocess.numeric_preprocess import preprocess_numeric_data
from preprocess.categorical_preprocess import preprocess_categorical_data
# from text_preprocess import preprocess_text_data
import os
import json

# ì „ì²˜ë¦¬ê¸°ì—ì„œ ì‚¬ìš©í•˜ëŠ” PKë§µì„ íŒŒì´í”„ë¼ì¸ì—ì„œë„ ì •ì˜
TABLE_PK_MAP = {
    'notice': ['bidntceno', 'bidntceord'],
    'company': ['bizno']
}

class DataPreprocessor:
    """ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.numeric_preprocessor = preprocess_numeric_data
        self.categorical_preprocessor = preprocess_categorical_data
        # self.text_preprocessor = preprocess_text_data

        self._load_metadata()

    def _load_metadata(self):
        """ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° ì»¬ëŸ¼ ë¶„ë¥˜"""
        import os
        import pandas as pd
        from dotenv import load_dotenv

        load_dotenv()
        metadata_file = os.getenv("METADATA_FILE_PATH")
        use_keyword = os.getenv("METADATA_USE_KEYWORD")

        try:
            meta_df = pd.read_csv(metadata_file, dtype=str)
            # ì‚¬ìš© ì—¬ë¶€ê°€ Yì¸ ë°ì´í„°ë§Œ í•„í„°ë§
            use_df = meta_df[meta_df[use_keyword].str.upper() == 'Y']

            # í…Œì´ë¸”ë³„ PK ì •ì˜ (query_helperì™€ ë™ì¼)
            table_pk_map = {
                'notice': ['bidntceno', 'bidntceord'],
                'company': ['bizno']
            }

            # í…Œì´ë¸”ë³„ ì»¬ëŸ¼ ë¶„ë¥˜
            self.column_types = {}

            for table_name in ['notice', 'company']:
                table_meta = use_df[use_df['í…Œì´ë¸”ëª…'] == table_name]

                self.column_types[table_name] = {
                    'pk': table_pk_map.get(table_name, []),  # PK ì»¬ëŸ¼ ì¶”ê°€
                    'numeric': [],
                    'categorical': [],
                    'text': []
                }

                # PK ì»¬ëŸ¼ ëª©ë¡
                pk_columns = set(table_pk_map.get(table_name, []))

                for _, row in table_meta.iterrows():
                    col_name = row['ì»¬ëŸ¼ëª…']

                    # PK ì»¬ëŸ¼ì€ ê±´ë„ˆë›°ê¸°
                    if col_name in pk_columns:
                        continue

                    data_type = row['íƒ€ì…'].lower()
                    categorical_flag = row.get('ë²”ì£¼í˜• ì—¬ë¶€')

                    # ìˆ˜ì¹˜í˜• ë¶„ë¥˜
                    if any(numeric_type in data_type for numeric_type in
                           ['integer', 'bigint', 'numeric', 'double precision', 'int', 'float']):
                        self.column_types[table_name]['numeric'].append(col_name)

                    # í…ìŠ¤íŠ¸/ë²”ì£¼í˜• ë¶„ë¥˜
                    elif any(text_type in data_type for text_type in
                             ['text', 'character', 'varchar', 'char']):
                        if categorical_flag == 'Y':
                            self.column_types[table_name]['categorical'].append(col_name)
                        else:
                            self.column_types[table_name]['text'].append(col_name)

            print("âœ… ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì»¬ëŸ¼ ë¶„ë¥˜ ì™„ë£Œ:")
            for table in self.column_types:
                print(f"  ğŸ“‹ {table}: PK {len(self.column_types[table]['pk'])}ê°œ, "
                      f"ìˆ˜ì¹˜í˜• {len(self.column_types[table]['numeric'])}ê°œ, "
                      f"ë²”ì£¼í˜• {len(self.column_types[table]['categorical'])}ê°œ, "
                      f"í…ìŠ¤íŠ¸ {len(self.column_types[table]['text'])}ê°œ")

        except Exception as e:
            print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ ì„¤ì •
            self.column_types = {
                'notice': {'pk': ['bidntceno', 'bidntceord'], 'numeric': [], 'categorical': [], 'text': []},
                'company': {'pk': ['bizno'], 'numeric': [], 'categorical': [], 'text': []}
            }


    def preprocess_dataframe(self, df, table_type):
        """
        ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬ (notice, company ê³µí†µ)

        Args:
            df: ì „ì²˜ë¦¬í•  ë°ì´í„°í”„ë ˆì„
            table_type: 'notice' ë˜ëŠ” 'company'

        Returns:
            preprocessed_df: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        """
        if df is None or df.empty:
            return df

        print(f"ğŸ”„ {table_type} ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")

        # í•´ë‹¹ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ íƒ€ì… ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        table_columns = self.column_types.get(table_type, {})

        # 1. ìˆ˜ì¹˜í˜• ë°ì´í„° ì „ì²˜ë¦¬
        numeric_cols = [col for col in table_columns.get('numeric', []) if col in df.columns]
        if numeric_cols:
            pk_cols = self.column_types.get(table_type, {}).get('pk', [])
            numeric_work_df = df[pk_cols + numeric_cols].copy()
            processed_numeric = self.numeric_preprocessor(numeric_work_df, table_type=table_type)
            df = df.drop(columns=numeric_cols).merge(processed_numeric, on=pk_cols, how='left')


        # 2. ë²”ì£¼í˜• ë°ì´í„° ì „ì²˜ë¦¬
        categorical_cols = [col for col in table_columns.get('categorical', []) if col in df.columns]
        if categorical_cols:
            pk_cols = self.column_types.get(table_type, {}).get('pk', [])
            categorical_work_df = df[pk_cols + categorical_cols].copy()
            processed_categorical = self.categorical_preprocessor(categorical_work_df, table_type=table_type)
            df = df.drop(columns=categorical_cols).merge(processed_categorical, on=pk_cols, how='left')


        # 3. í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬
        text_cols = [col for col in table_columns.get('text', []) if col in df.columns]
        if text_cols:
            text_df = df[text_cols].copy()
            processed_text = self.text_preprocessor(text_df, table_type=table_type)
            df[text_cols] = processed_text[text_cols]

        print(f"âœ… {table_type} ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
        return df



def get_notice_full_data(notice_id_tuple: List[Tuple[str, str]]) -> dict:
    """íŠ¹ì • ê³µê³ ì— ëŒ€í•œ notice, bid, company ë°ì´í„° ì¡°íšŒ"""
    db_connector = DatabaseConnector()
    helper = QueryHelper(db_connector)

    try:
        notice_data = helper.get_notice_by_ids([notice_id_tuple])
        bid_data = helper.get_bids_by_notice_ids([notice_id_tuple])

        company_data = None
        if not bid_data.empty:
            company_ids = bid_data['bidprccorpbizrno'].unique().tolist()
            company_data = helper.get_companies_by_ids(company_ids)

        return {
            'notice': notice_data,
            'bid': bid_data,
            'company': company_data
        }
    finally:
        db_connector.close()


def preprocess_pipeline(notice_id_tuple):
    """
    ì „ì²´ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

    Args:
        notice_id_tuple: ('20240406546', '000') í˜•íƒœì˜ ê³µê³  ID

    Returns:
        dict: {'notice': preprocessed_df, 'bid': df, 'company': preprocessed_df}
    """
    print(f"ğŸš€ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {notice_id_tuple}")

    # 1. ì›ë³¸ ë°ì´í„° ì¡°íšŒ
    raw_data = get_notice_full_data(notice_id_tuple)

    # 2. ì „ì²˜ë¦¬ê¸° ìƒì„±
    preprocessor = DataPreprocessor()

    # 3. notice, company ë°ì´í„° ì „ì²˜ë¦¬
    preprocessed_notice = preprocessor.preprocess_dataframe(raw_data['notice'], 'notice')
    preprocessed_company = preprocessor.preprocess_dataframe(raw_data['company'], 'company')


    print("âœ… ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")

    return {
        'notice': preprocessed_notice,
        'bid': raw_data['bid'],
        'company': preprocessed_company
    }


def get_multiple_notices_data(notice_ids: List[Tuple[str, str]]) -> dict:
    """
    ì—¬ëŸ¬ ê³µê³ ì— ëŒ€í•œ notice, bid, company ë°ì´í„° ì¡°íšŒ ë° í†µí•©

    Args:
        notice_ids: [(bidntceno, bidntceord), ...] í˜•íƒœì˜ ê³µê³  ID ë¦¬ìŠ¤íŠ¸

    Returns:
        dict: {'notice': combined_notice_df, 'bid': combined_bid_df, 'company': combined_company_df}
    """
    db_connector = DatabaseConnector()
    helper = QueryHelper(db_connector)

    import os

    try:
        all_notice_data = []
        all_bid_data = []
        all_company_ids = set()

        print(f"ğŸ”„ {len(notice_ids)}ê°œ ê³µê³  ë°ì´í„° ì¡°íšŒ ì¤‘...")

        for i, notice_id in enumerate(notice_ids, 1):
            print(f"  ğŸ“‹ {i}/{len(notice_ids)}: {notice_id}")

            # ê° ê³µê³ ë³„ ë°ì´í„° ì¡°íšŒ
            notice_data = helper.get_notice_by_ids([notice_id])
            bid_data = helper.get_bids_by_notice_ids([notice_id])

            if not notice_data.empty:
                all_notice_data.append(notice_data)

            if not bid_data.empty:
                all_bid_data.append(bid_data)
                # ì—…ì²´ ID ìˆ˜ì§‘
                company_ids = bid_data['bidprccorpbizrno'].unique()
                all_company_ids.update(company_ids)

        # ë°ì´í„° í†µí•©
        combined_notice = pd.concat(all_notice_data, ignore_index=True) if all_notice_data else pd.DataFrame()
        combined_bid = pd.concat(all_bid_data, ignore_index=True) if all_bid_data else pd.DataFrame()

        # ì—…ì²´ ë°ì´í„° ì¡°íšŒ (ì¤‘ë³µ ì œê±°ëœ ì—…ì²´ IDë¡œ)
        combined_company = None
        if all_company_ids:
            company_ids_list = list(all_company_ids)
            combined_company = helper.get_companies_by_ids(company_ids_list)

        print(f"âœ… ë°ì´í„° í†µí•© ì™„ë£Œ:")
        print(f"  ğŸ“Š ê³µê³ : {len(combined_notice)}í–‰")
        print(f"  ğŸ’° íˆ¬ì°°: {len(combined_bid)}í–‰")
        print(f"  ğŸ¢ ì—…ì²´: {len(combined_company) if combined_company is not None else 0}í–‰")

        # CSV íŒŒì¼ë¡œ ì €ì¥ - ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
        output_dir = os.path.abspath("output/multiple")
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í„°ë¦¬ ìƒì„±: {output_dir}")

        if not combined_notice.empty:
            notice_path = os.path.join(output_dir, "multiple_notices.csv")
            combined_notice.to_csv(notice_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ“ ê³µê³  ë°ì´í„° ì €ì¥: {notice_path}")

        if not combined_bid.empty:
            bid_path = os.path.join(output_dir, "multiple_bids.csv")
            combined_bid.to_csv(bid_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ“ íˆ¬ì°° ë°ì´í„° ì €ì¥: {bid_path}")

        if combined_company is not None and not combined_company.empty:
            company_path = os.path.join(output_dir, "multiple_companies.csv")
            combined_company.to_csv(company_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ“ ì—…ì²´ ë°ì´í„° ì €ì¥: {company_path}")

        return {
            'notice': combined_notice,
            'bid': combined_bid,
            'company': combined_company
        }

    finally:
        db_connector.close()


def test_multiple_notices_preprocessing():
    """10ê°œ ê³µê³  ë°ì´í„°ë¡œ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""

    # í…ŒìŠ¤íŠ¸ìš© ê³µê³  ID ëª©ë¡
    notice_ids = [
        ("20240406546", "000"),
        ("20240406548", "000"),
        ("20240406553", "000"),
        ("20240406556", "000"),
        ("20240406557", "000"),
        ("20140228597", "000"),
        ("20240406558", "000"),
        ("20140232077", "000"),
        ("20240406559", "000"),
        ("20240406563", "000")
    ]

    # 1. ì—¬ëŸ¬ ê³µê³  ë°ì´í„° ì¡°íšŒ
    print("ğŸš€ ë‹¤ì¤‘ ê³µê³  ë°ì´í„° ì¡°íšŒ ì‹œì‘")
    print("=" * 80)
    data = get_multiple_notices_data(notice_ids)
    
    # 2. ì „ì²˜ë¦¬ê¸° ìƒì„± ë° ì‹¤í–‰
    print("\nğŸš€ ì „ì²´ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
    print("=" * 80)
    preprocessor = DataPreprocessor()

    preprocessed_notice = preprocessor.preprocess_dataframe(data['notice'].copy(), 'notice')
    preprocessed_company = preprocessor.preprocess_dataframe(data['company'].copy(), 'company')
    
    # 3. ê²°ê³¼ ì €ì¥
    output_dir = "output/preprocessed"
    os.makedirs(output_dir, exist_ok=True)
    
    notice_path = os.path.join(output_dir, "final_preprocessed_notice.csv")
    company_path = os.path.join(output_dir, "final_preprocessed_company.csv")
    
    preprocessed_notice.to_csv(notice_path, index=False, encoding='utf-8-sig')
    preprocessed_company.to_csv(company_path, index=False, encoding='utf-8-sig')
    
    print("\nâœ… ìµœì¢… ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
    print(f"  - ê³µê³ : {notice_path}")
    print(f"  - ì—…ì²´: {company_path}")

    print("\nğŸ“‹ ìµœì¢… ê³µê³  ë°ì´í„° ìƒ˜í”Œ:")
    print(preprocessed_notice.head())


if __name__ == "__main__":
    # ë‹¤ì¤‘ ê³µê³  ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    test_multiple_notices_preprocessing()