# categorical_preprocess.py
import pandas as pd
import numpy as np
import json
from typing import Dict, Any, Optional, List
from pathlib import Path
import pickle

TABLE_PK_MAP = {
    'notice': ['bidntceno', 'bidntceord'],
    'company': ['bizno']
}

# íŠ¹ìˆ˜ í† í° ì •ì˜
NULL_TOKEN = '[NULL]'
RARE_TOKEN = '[RARE]'
UNKNOWN_TOKEN = '[UNKNOWN]'


class CategoricalPreprocessor:
    """
    ë²”ì£¼í˜• ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤ (Embedding Layer ìµœì í™”)
    - ëª¨ë“  ë³€ìˆ˜ë¥¼ ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    - í¬ì†Œ/ê²°ì¸¡/ë¯¸ì§€ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ì•ˆì •ì ì¸ ì²˜ë¦¬ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.
    - ëª¨ë¸ë§ì— í•„ìš”í•œ ëª¨ë“  ë©”íƒ€ë°ì´í„°ë¥¼ jsonìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """

    def __init__(self, config: Dict[str, Dict[str, Any]], table_pk_map: Optional[Dict[str, List[str]]] = None):
        self.cfg = config
        self.mappings = {}  # ì¸ì½”ë”© ë§¤í•‘ ë° ë©”íƒ€ë°ì´í„° ì €ì¥
        self.is_fitted = False
        self.table_pk_map = table_pk_map if table_pk_map else TABLE_PK_MAP

    def fit(self, df_train: pd.DataFrame) -> 'CategoricalPreprocessor':
        print("ğŸ”„ ì „ë¬¸ê°€ ëª¨ë“œ: ë²”ì£¼í˜• ì „ì²˜ë¦¬ê¸° í•™ìŠµ ì‹œì‘...")
        for col in df_train.columns:
            if col not in self.cfg:
                continue

            col_cfg = self.cfg[col]
            col_data = df_train[col].copy().astype(str) # ì•ˆì •ì„±ì„ ìœ„í•´ ë¬¸ìì—´ë¡œ ë³€í™˜

            # 1. ê²°ì¸¡ê°’ ì²˜ë¦¬
            has_null = col_data.isnull().any()
            if has_null:
                col_data.fillna(NULL_TOKEN, inplace=True)

            # 2. í¬ì†Œ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ (Rare Label Handling)
            # ì¹´ë””ë„ë¦¬í‹°ê°€ ë„ˆë¬´ ë†’ì€ ë³€ìˆ˜ì˜ ë…¸ì´ì¦ˆë¥¼ ì¤„ì—¬ ëª¨ë¸ ì•ˆì •ì„± ë° ì„±ëŠ¥ í–¥ìƒ
            rare_threshold = col_cfg.get('rare_threshold', 0.0)
            if rare_threshold > 0:
                counts = col_data.value_counts(normalize=True)
                rare_labels = counts[counts < rare_threshold].index
                if len(rare_labels) > 0:
                    col_data[col_data.isin(rare_labels)] = RARE_TOKEN

            # 3. ìµœì¢… ì–´íœ˜(Vocabulary) ìƒì„± ë° ì¸ë±ì‹±
            # UNKNOWN í† í°ì„ í•­ìƒ ì–´íœ˜ì— í¬í•¨í•˜ì—¬, ì¶”ë¡  ì‹œ ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ì— ëŒ€ì‘
            unique_labels = col_data.unique().tolist()
            vocab = sorted([str(label) for label in unique_labels])
            
            # UNKNOWN í† í°ì´ ì–´íœ˜ì— ì—†ìœ¼ë©´ ì¶”ê°€
            if UNKNOWN_TOKEN not in vocab:
                vocab.append(UNKNOWN_TOKEN)

            # ìµœì¢… ë§¤í•‘ ì •ë³´ ë° ë©”íƒ€ë°ì´í„° ì €ì¥
            self.mappings[col] = {
                'map': {label: i for i, label in enumerate(vocab)},
                'vocab_size': len(vocab),
                'has_null': has_null,
                'has_rare': rare_threshold > 0 and len(rare_labels) > 0,
                'unknown_token_idx': vocab.index(UNKNOWN_TOKEN)
            }

        self.is_fitted = True
        print(f"âœ… í•™ìŠµ ì™„ë£Œ: {len(self.mappings)}ê°œ ë³€ìˆ˜ì— ëŒ€í•œ ì–´íœ˜ ë° ë©”íƒ€ë°ì´í„° ìƒì„±")
        return self

    def transform(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:
        if not self.is_fitted:
            raise ValueError("ë¨¼ì € fit()ì„ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë¸ë§ê³¼ ì „ì²˜ë¦¬ì˜ ê¸°ì¤€ì´ ë‹¤ë¥´ë©´ ì˜ˆì¸¡ì´ ë§ê°€ì§‘ë‹ˆë‹¤.")

        df_out = pd.DataFrame(index=df.index)
        
        pk_cols = self.table_pk_map.get(table_name, [])
        for pk in pk_cols:
            if pk in df.columns:
                df_out[pk] = df[pk]

        for col in df.columns:
            if col not in self.cfg or col in pk_cols:
                continue

            col_cfg = self.cfg[col]
            col_data = df[col].copy().astype(str)
            
            # 1. ê²°ì¸¡ê°’ í”Œë˜ê·¸ (ëª¨ë¸ì—ê²Œ ê²°ì¸¡ ì •ë³´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì•Œë ¤ì£¼ëŠ” ê²ƒì€ ì¤‘ìš”í•œ í”¼ì²˜ê°€ ë  ìˆ˜ ìˆìŒ)
            df_out[f'{col}_is_null'] = df[col].isnull().astype('float32')
            
            # 2. ê²°ì¸¡ê°’ í† í°í™”
            col_data.fillna(NULL_TOKEN, inplace=True)
            
            # 3. í•™ìŠµëœ ë§¤í•‘ìœ¼ë¡œ ì¸ì½”ë”©
            mapping_info = self.mappings.get(col, {})
            mapping = mapping_info.get('map', {})
            unknown_idx = mapping_info.get('unknown_token_idx', -1) # -1ì€ ì—ëŸ¬ í™•ì¸ìš©

            # mapì— ì—†ëŠ” ìƒˆë¡œìš´ ê°’ì€ ëª¨ë‘ unknown_idxë¡œ ëŒ€ì²´
            df_out[col] = col_data.map(mapping).fillna(unknown_idx).astype(int)

        return df_out

    def save(self, path: str):
        """
        ì „ì²˜ë¦¬ê¸° ê°ì²´(.pkl)ì™€ ëª¨ë¸ë§ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„°(.json)ë¥¼ í•¨ê»˜ ì €ì¥
        """
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        
        # 1. Pickle íŒŒì¼: ì „ì²˜ë¦¬ê¸° ì „ì²´ ê°ì²´ ì €ì¥
        with open(path, 'wb') as f:
            pickle.dump(self, f)
        print(f"âœ… ë²”ì£¼í˜• ì „ì²˜ë¦¬ê¸° ì €ì¥ ì™„ë£Œ: {path}")

        # 2. JSON íŒŒì¼: ëª¨ë¸ëŸ¬ë¥¼ ìœ„í•œ ëª…ì„¸ì„œ(_is_null ì»¬ëŸ¼ì€ í•­ìƒ ìƒì„±ë˜ë¯€ë¡œ ëª…ì‹œ ë¶ˆí•„ìš”)
        metadata_path = Path(path).with_suffix('.json')
        model_metadata = {
            col: {
                # ì„ë² ë”© ë ˆì´ì–´ì˜ input_dim ìœ¼ë¡œ ì‚¬ìš©
                'input_dim': info.get('vocab_size', 0), 
                # UNKNOWN í† í°ì´ ì–´íœ˜ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
                'has_unknown_token': UNKNOWN_TOKEN in info.get('map', {}),
                # NULL í† í°ì´ ì–´íœ˜ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
                'has_null_token': NULL_TOKEN in info.get('map', {}),
                 # RARE í† í°ì´ ì–´íœ˜ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
                'has_rare_token': RARE_TOKEN in info.get('map', {})
            } for col, info in self.mappings.items()
        }
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(model_metadata, f, indent=4)
        print(f"âœ… ëª¨ë¸ë§ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {metadata_path}")

    @classmethod
    def load(cls, path: str) -> 'CategoricalPreprocessor':
        with open(path, 'rb') as f:
            preprocessor = pickle.load(f)
        print(f"âœ… ë²”ì£¼í˜• ì „ì²˜ë¦¬ê¸° ë¡œë“œ ì™„ë£Œ: {path}")
        return preprocessor

def load_config(config_path: str) -> Dict[str, Dict[str, Any]]:
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)
        
def preprocess_categorical_data(df: pd.DataFrame, table_type: str) -> pd.DataFrame:
    config_path = f"meta/{table_type}_categorical_config.json"
    try:
        cfg = load_config(config_path)
        
        preprocessor = CategoricalPreprocessor(cfg)
        processed_df = preprocessor.fit(df).transform(df, table_type)
        
        preprocessor.save(f"models/{table_type}_categorical_preprocessor.pkl")
        
        print(f"âœ… {table_type} ë²”ì£¼í˜• ì „ì²˜ë¦¬ ì™„ë£Œ.")
        return processed_df
    except Exception as e:
        print(f"âŒ {table_type} ë²”ì£¼í˜• ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return df

if __name__ == '__main__':
    try:
        table_name = "notice"
        json_config_path = "meta/notice_categorical_config.json"
        
        # ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±
        if not Path(json_config_path).exists():
            sample_cfg = {
                "bidmethdnm": {
                    "encoding_method": "label",
                    "add_flag": True,
                    "null_strategy": "new_category"
                },
                "cntrctcnclsmthdnm": {
                    "encoding_method": "label",
                     "null_strategy": "mode"
                }
            }
            with open(json_config_path, 'w', encoding='utf-8') as f:
                json.dump(sample_cfg, f, indent=2)
            print(f"ğŸ“ ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±: {json_config_path}")

        df = pd.read_csv("output/multiple/multiple_notices.csv")
        
        config = load_config(json_config_path)
        
        # ì„¤ì • íŒŒì¼ì— ì •ì˜ëœ ì»¬ëŸ¼ ì¤‘ ì‹¤ì œ ë°ì´í„°ì— ìˆëŠ” ê²ƒë§Œ ì„ íƒ
        cat_cols = [c for c in config.keys() if c in df.columns]
        
        # PK ì»¬ëŸ¼ ì¶”ê°€
        pk_cols = [pk for pk in TABLE_PK_MAP.get(table_name, []) if pk in df.columns]
        
        # ì „ì²˜ë¦¬ì— ì‚¬ìš©í•  ì»¬ëŸ¼ ëª©ë¡ (PK + ë²”ì£¼í˜•)
        process_cols = pk_cols + cat_cols
        
        print(f"ğŸ”„ PK {pk_cols}ì™€ ë²”ì£¼í˜• {cat_cols} ì»¬ëŸ¼ ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        result = preprocess_categorical_data(df[process_cols], table_name)
        
        print("\\nâœ… ì „ì²˜ë¦¬ í›„ ë°ì´í„°:")
        print(result.head())
        
        output_path = "output/preprocessed/notice_categorical_test.csv"
        result.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\\nğŸ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {output_path}")

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
