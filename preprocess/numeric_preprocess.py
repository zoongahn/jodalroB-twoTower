# numeric_preprocess.py
import pandas as pd
import numpy as np
import json
import pickle
from typing import Dict, Any, Optional, List
from pathlib import Path
import os

TABLE_PK_MAP = {
    'notice': ['bidntceno', 'bidntceord'],  # ê³µê³  í…Œì´ë¸” PK
    'company': ['bizno']  # ì—…ì²´ í…Œì´ë¸” PK
}


class NumericPreprocessor:
    """ìˆ˜ì¹˜í˜• ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, config: Dict[str, Dict[str, Any]], table_pk_map: Optional[Dict[str, List[str]]] = None):
        """
        Args:
            config: JSON ì„¤ì • ë”•ì…”ë„ˆë¦¬ {ì»¬ëŸ¼ëª…: {ì„¤ì •ì˜µì…˜ë“¤}}
        """
        self.cfg = config
        self.stats = {}  # ì»¬ëŸ¼ë³„ í†µê³„ ì €ì¥: mean, std, clip_bounds ë“±
        self.is_fitted = False

        self.table_pk_map = table_pk_map


    def fit(self, df_train: pd.DataFrame) -> 'NumericPreprocessor':
        """
        í›ˆë ¨ ë°ì´í„°ë¡œë¶€í„° í†µê³„ ê³„ì‚° (ê¸°ì¤€ ì¡ê¸°)

        Args:
            df_train: í›ˆë ¨ ë°ì´í„°í”„ë ˆì„

        Returns:
            self
        """
        print("ğŸ”„ ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ê¸° í•™ìŠµ ì¤‘...")

        for col in df_train.columns:
            if col not in self.cfg:
                continue

            col_cfg = self.cfg[col]
            col_data = df_train[col].copy()

            # ì»¬ëŸ¼ë³„ í†µê³„ ì´ˆê¸°í™”
            self.stats[col] = {}

            # 1. ê²°ì¸¡ê°’ ì²˜ë¦¬ë¥¼ ìœ„í•œ í†µê³„
            if col_cfg.get('fill') == 'median':
                self.stats[col]['fill_value'] = col_data.median()
            elif col_cfg.get('fill') == 'mode':
                self.stats[col]['fill_value'] = col_data.mode().iloc[0] if not col_data.mode().empty else 0
            elif isinstance(col_cfg.get('fill'), (int, float)):
                self.stats[col]['fill_value'] = col_cfg['fill']
            else:
                self.stats[col]['fill_value'] = 0

            # ê²°ì¸¡ê°’ ì±„ìš°ê¸° (í†µê³„ ê³„ì‚°ì„ ìœ„í•´)
            col_data = col_data.fillna(self.stats[col]['fill_value'])

            # 2. í´ë¦¬í•‘ ê²½ê³„ ê³„ì‚°
            if 'clip' in col_cfg:  # ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜
                p_low, p_high = col_cfg['clip']
                self.stats[col]['clip_low'] = np.percentile(col_data, p_low)
                self.stats[col]['clip_high'] = np.percentile(col_data, p_high)
            elif 'clip_abs' in col_cfg:  # ì ˆëŒ€ê°’ ê¸°ë°˜
                self.stats[col]['clip_low'] = col_cfg['clip_abs'][0]
                self.stats[col]['clip_high'] = col_cfg['clip_abs'][1]

            # í´ë¦¬í•‘ ì ìš© (log1p, scale ê³„ì‚°ì„ ìœ„í•´)
            if 'clip_low' in self.stats[col]:
                if col_cfg.get('clip_to_null', False):
                    # ë²”ìœ„ ë°–ì€ nullë¡œ ì²˜ë¦¬
                    mask = (col_data < self.stats[col]['clip_low']) | (col_data > self.stats[col]['clip_high'])
                    col_data[mask] = np.nan
                else:
                    # ë²”ìœ„ ë°–ì€ ê²½ê³„ê°’ìœ¼ë¡œ í´ë¦¬í•‘
                    col_data = col_data.clip(self.stats[col]['clip_low'], self.stats[col]['clip_high'])

            # 3. log1p ë³€í™˜ (ìŠ¤ì¼€ì¼ë§ í†µê³„ ê³„ì‚°ì„ ìœ„í•´)
            if col_cfg.get('log1p', False):
                # log1pëŠ” ìŒìˆ˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ ìµœì†Œê°’ ë³´ì •
                min_val = col_data.min()
                if min_val <= 0:
                    self.stats[col]['log1p_offset'] = abs(min_val) + 1
                    col_data_log = np.log1p(col_data + self.stats[col]['log1p_offset'])
                else:
                    self.stats[col]['log1p_offset'] = 0
                    col_data_log = np.log1p(col_data)
                col_data_for_scale = col_data_log
            else:
                col_data_for_scale = col_data

            # 4. ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ í†µê³„
            if col_cfg.get('scale') == 'zscore':
                self.stats[col]['mean'] = col_data_for_scale.mean()
                self.stats[col]['std'] = col_data_for_scale.std()
                if self.stats[col]['std'] == 0:
                    self.stats[col]['std'] = 1  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
            elif col_cfg.get('scale') == 'minmax':
                self.stats[col]['min'] = col_data_for_scale.min()
                self.stats[col]['max'] = col_data_for_scale.max()
                if self.stats[col]['min'] == self.stats[col]['max']:
                    self.stats[col]['max'] = self.stats[col]['min'] + 1  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€

        self.is_fitted = True
        print(f"âœ… ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ê¸° í•™ìŠµ ì™„ë£Œ: {len(self.stats)}ê°œ ì»¬ëŸ¼")
        return self

    def transform(self, df: pd.DataFrame, table_name:str) -> pd.DataFrame:
        """
        í•™ìŠµëœ í†µê³„ë¡œ ë°ì´í„° ë³€í™˜

        Args:
            df: ë³€í™˜í•  ë°ì´í„°í”„ë ˆì„
            table_name: í…Œì´ë¸” ì´ë¦„
        Returns:
            ë³€í™˜ëœ ë°ì´í„°í”„ë ˆì„
        """
        if not self.is_fitted:
            raise ValueError("ë¨¼ì € fit()ì„ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.")

        original_order = list(df.columns)

        # 0) PK í™•ì¸ ë° ë³´ì¡´
        pk_cols = self.table_pk_map.get(table_name, [])
        if pk_cols:
            missing = [c for c in pk_cols if c not in df.columns]
            if missing:
                raise KeyError(f"[{table_name}] PK ì»¬ëŸ¼ ëˆ„ë½: {missing}")
        else:
            pk_cols = []

        processed = {}

        for pk in pk_cols:
            processed[pk] = df[pk].copy()

        for col in df.columns:
            if col in pk_cols:
                continue
            if col not in self.cfg or col not in self.stats:
                continue

            col_cfg = self.cfg[col]
            col_stats = self.stats[col]
            col_data = df[col].copy()

            # 1. ê²°ì¸¡ê°’ í”Œë˜ê·¸ ì¶”ê°€
            if col_cfg.get('add_flag', False):
                processed[f'{col}_is_null'] = col_data.isnull().astype('float32')

            # 2. ê²°ì¸¡ê°’ ì±„ìš°ê¸°
            col_data = col_data.fillna(col_stats['fill_value'])

            # 3. í´ë¦¬í•‘
            if 'clip_low' in col_stats:
                if col_cfg.get('clip_to_null', False):
                    # ë²”ìœ„ ë°–ì€ nullë¡œ ì²˜ë¦¬
                    mask = (col_data < col_stats['clip_low']) | (col_data > col_stats['clip_high'])
                    col_data[mask] = np.nan
                    # nullë¡œ ì²˜ë¦¬ëœ ê°’ë“¤ì„ fill_valueë¡œ ì¬ì±„ìš°ê¸°
                    col_data = col_data.fillna(col_stats['fill_value'])
                else:
                    # ë²”ìœ„ ë°–ì€ ê²½ê³„ê°’ìœ¼ë¡œ í´ë¦¬í•‘
                    col_data = col_data.clip(col_stats['clip_low'], col_stats['clip_high'])

            # 4. log1p ë³€í™˜
            if col_cfg.get('log1p', False):
                col_data = np.log1p(col_data + col_stats.get('log1p_offset', 0))

            # 5. ìŠ¤ì¼€ì¼ë§
            if col_cfg.get('scale') == 'zscore':
                col_data = (col_data - col_stats['mean']) / col_stats['std']
            elif col_cfg.get('scale') == 'minmax':
                col_data = (col_data - col_stats['min']) / (col_stats['max'] - col_stats['min'])

            # 6. float32ë¡œ ë³€í™˜
            processed[col] = col_data.astype('float32')

        # ì›ë˜ ìˆœì„œëŒ€ë¡œ DataFrame êµ¬ì„±
        df_out = pd.DataFrame({col: processed[col] for col in original_order if col in processed})

        # ì¶”ê°€ì ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ *_is_null í”Œë˜ê·¸ ì»¬ëŸ¼ ë’¤ì— ë¶™ì´ê¸°
        extra_cols = [c for c in processed.keys() if c not in df_out.columns]
        for c in extra_cols:
            df_out[c] = processed[c]

        return df_out


    def save(self, path: str):
        """ì „ì²˜ë¦¬ê¸° ì €ì¥"""
        save_data = {
            'config': self.cfg,
            'stats': self.stats,
            'is_fitted': self.is_fitted
        }

        Path(path).parent.mkdir(parents=True, exist_ok=True)
        with open(path, 'wb') as f:
            pickle.dump(save_data, f)
        print(f"âœ… ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ê¸° ì €ì¥ ì™„ë£Œ: {path}")

    @classmethod
    def load(cls, path: str) -> 'NumericPreprocessor':
        """ì „ì²˜ë¦¬ê¸° ë¡œë“œ"""
        with open(path, 'rb') as f:
            save_data = pickle.load(f)

        preprocessor = cls(save_data['config'])
        preprocessor.stats = save_data['stats']
        preprocessor.is_fitted = save_data['is_fitted']

        print(f"âœ… ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ê¸° ë¡œë“œ ì™„ë£Œ: {path}")
        return preprocessor


def load_config(config_path: str) -> Dict[str, Dict[str, Any]]:
    """JSON ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def preprocess_numeric_data(df: pd.DataFrame, table_type: str) -> pd.DataFrame:
    """
    pipeline.pyì—ì„œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜

    Args:
        df: ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        table_type: 'notice' ë˜ëŠ” 'company'

    Returns:
        ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
    """
    # ì„¤ì • íŒŒì¼ ê²½ë¡œ
    config_path = f"meta/{table_type}_numeric_config.json"


    try:
        # ì„¤ì • ë¡œë“œ
        cfg = load_config(config_path)

        pk_cols = [c for c in TABLE_PK_MAP[table_type] if c in df.columns]

        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
        feat_cols = [c for c in cfg.keys() if c in df.columns]

        # â‘¢ PK + í”¼ì²˜ë§Œ ì¶”ì¶œí•´ ì „ì²˜ë¦¬ê¸°ë¡œ ë„˜ê¹€
        use_cols = pk_cols + feat_cols
        work = df[use_cols].copy()

        # ì „ì²˜ë¦¬ ìˆ˜í–‰ (í•™ìŠµ ëª¨ë“œ - fit_transform ì‚¬ìš©)
        preprocessor = NumericPreprocessor(cfg, TABLE_PK_MAP)
        processed_df = preprocessor.fit(work).transform(work, table_type)

        # ì „ì²˜ë¦¬ê¸° ì €ì¥ (ë‚˜ì¤‘ì— ë™ì¼í•œ ë³€í™˜ì„ ìœ„í•´)
        preprocessor.save(f"models/{table_type}_numeric_preprocessor.pkl")

        print(f"âœ… {table_type} ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ì™„ë£Œ: {len(cfg)}ê°œ ì»¬ëŸ¼")
        return processed_df

    except Exception as e:
        print(f"âŒ {table_type} ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return df


# 1) PK ë³´ì¡´ì„ ê³ ë ¤í•œ ì„œë¸Œì…‹ ì¶”ì¶œ
def _collect_pk_and_numeric(df: pd.DataFrame, table_name: str, config: dict):
    # (a) PK ì»¬ëŸ¼ í™•ë³´ (ì¸ë±ìŠ¤ì— ìˆìœ¼ë©´ reset_index)
    pk_cols = TABLE_PK_MAP.get(table_name, [])
    work = df

    # ì¸ë±ìŠ¤ì— PKê°€ ìˆ¨ì–´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³µêµ¬
    if isinstance(work.index, pd.MultiIndex):
        if set(pk_cols).issubset(set([n for n in work.index.names if n])):
            work = work.reset_index()
    elif work.index.name in pk_cols:
        work = work.reset_index()

    # (b) ì‹¤ì œ ì¡´ì¬í•˜ëŠ” PKë§Œ ìœ ì§€
    pk_cols = [c for c in pk_cols if c in work.columns]

    # (c) ìˆ˜ì¹˜í˜• ëŒ€ìƒ ì»¬ëŸ¼ (ì„¤ì • íŒŒì¼ ê¸°ì¤€)
    numeric_cols = [col for col in config.keys() if col in work.columns]

    # (d) PK + ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ í•©ì¹˜ê¸°(ì¤‘ë³µ ì œê±°, PKê°€ ì•ì— ì˜¤ë„ë¡)
    use_cols = pk_cols + [c for c in numeric_cols if c not in pk_cols]

    # ì•ˆì „ì¥ì¹˜: ìµœì†Œ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
    if not use_cols:
        raise KeyError(f"[{table_name}] ì‚¬ìš©í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (PK:{TABLE_PK_MAP.get(table_name, [])}, cfg keys:{list(config.keys())[:5]}...)")

    return work[use_cols].copy(), pk_cols


if __name__ == "__main__":
    import os

    # CSV íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸
    try:
        table_name = "notice"
        json_config_path = "meta/notice_numeric_config.json"

        # CSV ë¡œë“œ
        df = pd.read_csv("output/multiple/multiple_notices.csv")
        print(f"ğŸ“„ CSV ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰ Ã— {len(df.columns)}ì—´")

        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (ì„¤ì • íŒŒì¼ ê¸°ì¤€)
        config = load_config(json_config_path)
        numeric_df, pk_cols = _collect_pk_and_numeric(df, table_name, config)

        # ì „ì²˜ë¦¬ ì‹¤í–‰
        print("\n" + "=" * 100)
        print("ğŸ”„ ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ì‹¤í–‰ ì¤‘...")
        print("=" * 100)

        result = preprocess_numeric_data(numeric_df, table_name)

        print("\n" + "=" * 100)
        print("âœ… ì „ì²˜ë¦¬ í›„ ë°ì´í„°")
        print("=" * 100)
        print(f"ì»¬ëŸ¼ ìˆ˜: {len(result.columns)}ê°œ")


        # ë³€í™” ìš”ì•½
        print("\n" + "=" * 100)
        print("ğŸ“‹ ì „ì²˜ë¦¬ ë³€í™” ìš”ì•½")
        print("=" * 100)

        original_cols = set(numeric_df.columns)
        new_cols = set(result.columns)
        added_cols = new_cols - original_cols

        print(f"ì›ë³¸ ì»¬ëŸ¼ ìˆ˜: {len(original_cols)}ê°œ")
        print(f"ì „ì²˜ë¦¬ í›„ ì»¬ëŸ¼ ìˆ˜: {len(new_cols)}ê°œ")
        print(f"ì¶”ê°€ëœ ì»¬ëŸ¼ ìˆ˜: {len(added_cols)}ê°œ")


        # í…ŒìŠ¤íŠ¸ìš© ì €ì¥
        os.makedirs("output/preprocessed", exist_ok=True)
        test_output_path = "output/preprocessed/notice_numeric_test.csv"
        result.to_csv(test_output_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {test_output_path}")

    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback

        traceback.print_exc()